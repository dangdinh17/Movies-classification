{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import os\n",
    "from nltk import wordpunct_tokenize\n",
    "import re\n",
    "import nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_csv('./dataset/users.dat', sep='::',\n",
    "                        engine='python',\n",
    "                        names=['userid', 'gender', 'age', 'occupation', 'zip']).set_index('userid')\n",
    "ratings = pd.read_csv('./dataset/ratings.dat', engine='python',\n",
    "                          sep='::', names=['userid', 'movieid', 'rating', 'timestamp'])\n",
    "movies_train = pd.read_csv('./dataset/movies_train.dat', engine='python',\n",
    "                         sep='::', names=['movieid', 'title', 'genre'], encoding='latin-1', index_col=False).set_index('movieid')\n",
    "movies_test = pd.read_csv('./dataset/movies_test.dat', engine='python',\n",
    "                         sep='::', names=['movieid', 'title', 'genre'], encoding='latin-1', index_col=False).set_index('movieid')                         \n",
    "movies_train['genre'] = movies_train.genre.str.split('|')\n",
    "movies_test['genre'] = movies_test.genre.str.split('|')\n",
    "\n",
    "users.age = users.age.astype('category')\n",
    "users.gender = users.gender.astype('category')\n",
    "users.occupation = users.occupation.astype('category')\n",
    "ratings.movieid = ratings.movieid.astype('category')\n",
    "ratings.userid = ratings.userid.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import importlib\n",
    "sys.path.insert(0, './params')\n",
    "sys.path.insert(1, './metrics')\n",
    "import param_rating\n",
    "import map_at_k\n",
    "importlib.reload(param_rating)\n",
    "importlib.reload(map_at_k)\n",
    "import pickle\n",
    "\n",
    "import neural_metrics\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from tensorflow.keras import layers, models\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "from keras.saving import save_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelByTitle:\n",
    "    def __init__(self,movie_train) :\n",
    "        self.movie_train=movie_train.copy()\n",
    "        self.movie_test=None\n",
    "        self.submission_combined=None\n",
    "        self.vectors_labels=None\n",
    "    def tokenize(self,text):\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)\n",
    "        text = text.lower()\n",
    "        tokens = wordpunct_tokenize(text)\n",
    "        tokens = tokens[:-1] # remove last token because it is the year which maybe is not useful\n",
    "        return tokens\n",
    "\n",
    "    def create_vocab(self):\n",
    "        df = self.movie_train.copy()\n",
    "        arr_title = df['title'].tolist()\n",
    "        vocab = set()\n",
    "        for title in arr_title:\n",
    "            tokens = self.tokenize(title)\n",
    "            vocab.update(tokens)\n",
    "        vocab = list(vocab)\n",
    "        pad_token = '<PAD>'\n",
    "        unk_token = '<UNK>'\n",
    "        vocab.append(pad_token)\n",
    "        vocab.append(unk_token)\n",
    "        return vocab\n",
    "\n",
    "    def __preprocess_data_train(self):\n",
    "        self.movie_train.reset_index(inplace=True)\n",
    "        vocab=self.create_vocab()\n",
    "        self.movie_train['title_tokens'] = [self.tokenize(x) for x in self.movie_train.title]\n",
    "        # create vocab\n",
    "        pad_token = '<PAD>'\n",
    "        unk_token = '<UNK>'\n",
    "        token2idx = {token: idx for idx, token in enumerate(vocab)}\n",
    "        # Create a binary vector for each word in each sentence\n",
    "        MAX_LENGTH = 7\n",
    "        vectors = []\n",
    "        for title_tokens in self.movie_train.title_tokens.tolist():\n",
    "            if len(title_tokens) < MAX_LENGTH:\n",
    "                num_pad = MAX_LENGTH - len(title_tokens)\n",
    "                for _ in range(num_pad):\n",
    "                    title_tokens.append(pad_token)\n",
    "            else:\n",
    "                title_tokens = title_tokens[:MAX_LENGTH]\n",
    "            title_vectors = np.zeros(len(vocab))\n",
    "            for word in title_tokens:\n",
    "                if word in vocab:\n",
    "                    title_vectors[token2idx[word]] = 1\n",
    "                else:\n",
    "                    title_vectors[token2idx[unk_token]] = 1\n",
    "\n",
    "            vectors.append(np.array(title_vectors))\n",
    "        self.movie_train['vectors'] = vectors \n",
    "\n",
    "        #preprocess label\n",
    "        vectors_genre=[]\n",
    "        for genre in self.movie_train.genre.tolist():\n",
    "            genre_vector = np.zeros(len(param_rating.genre2idx))\n",
    "            for g in genre:\n",
    "                genre_vector[param_rating.genre2idx[g]] = 1\n",
    "            vectors_genre.append(genre_vector)\n",
    "        self.movie_train['genre_vectors']=vectors_genre\n",
    "\n",
    "        genre_df = pd.DataFrame(self.movie_train['genre_vectors'].tolist(), columns=param_rating.genre2idx.keys())\n",
    "        self.movie_train = pd.concat([self.movie_train, genre_df], axis=1)  \n",
    "\n",
    "        self.x_train=np.expand_dims(self.movie_train['vectors'], 0)\n",
    "        self.x_train=np.vstack(np.ravel(np.ravel(self.x_train))) \n",
    "        self.y_train=np.expand_dims(self.movie_train['genre_vectors'], 0)\n",
    "        self.y_train=np.vstack(np.ravel(np.ravel(self.y_train))) \n",
    "\n",
    "        \n",
    "    def __preprocess_data_test(self,movie_test):\n",
    "        self.movie_test=movie_test.copy()\n",
    "        self.movie_test.reset_index(inplace=True)\n",
    "        self.movie_test['title_tokens'] = [self.tokenize(x) for x in self.movie_test.title]\n",
    "        # create vocab\n",
    "        vocab=self.create_vocab()\n",
    "\n",
    "        pad_token = '<PAD>'\n",
    "        unk_token = '<UNK>'\n",
    "        token2idx = {token: idx for idx, token in enumerate(vocab)}\n",
    "        # Create a binary vector for each word in each sentence\n",
    "        MAX_LENGTH = 7\n",
    "        vectors = []\n",
    "        for title_tokens in self.movie_test.title_tokens.tolist():\n",
    "            if len(title_tokens) < MAX_LENGTH:\n",
    "                num_pad = MAX_LENGTH - len(title_tokens)\n",
    "                for _ in range(num_pad):\n",
    "                    title_tokens.append(pad_token)\n",
    "            else:\n",
    "                title_tokens = title_tokens[:MAX_LENGTH]\n",
    "            title_vectors = np.zeros(len(vocab))\n",
    "            for word in title_tokens:\n",
    "                if word in vocab:\n",
    "                    title_vectors[token2idx[word]] = 1\n",
    "                else:\n",
    "                    title_vectors[token2idx[unk_token]] = 1\n",
    "\n",
    "            vectors.append(np.array(title_vectors))\n",
    "        self.movie_test['vectors'] = vectors \n",
    "\n",
    "        #preprocess label\n",
    "        vectors_genre=[]\n",
    "        for genre in self.movie_test.genre.tolist():\n",
    "            genre_vector = np.zeros(len(param_rating.genre2idx))\n",
    "            for g in genre:\n",
    "                genre_vector[param_rating.genre2idx[g]] = 1\n",
    "            vectors_genre.append(genre_vector)\n",
    "        self.movie_test['genre_vectors']=vectors_genre\n",
    "\n",
    "        genre_test = pd.DataFrame(self.movie_test['genre_vectors'].tolist(), columns=param_rating.genre2idx.keys())\n",
    "        self.movie_test = pd.concat([self.movie_test, genre_test], axis=1)\n",
    "\n",
    "        self.x_test=np.expand_dims(self.movie_test['vectors'], 0)\n",
    "        self.x_test=np.vstack(np.ravel(np.ravel(self.x_test))) \n",
    "        self.y_test=np.expand_dims(self.movie_test['genre_vectors'], 0)\n",
    "        self.y_test=np.vstack(np.ravel(np.ravel(self.y_test))) \n",
    "    def preprocess_data(self):\n",
    "        self.__preprocess_data_train()\n",
    "    def train_model(self):\n",
    "        #Logistic Regression with BorderlineSMOTE algorithm\n",
    "        logreg_list=[]\n",
    "        # for label in param_rating.genre2idx.keys():\n",
    "        #     logreg = LogisticRegression(C=1.56)\n",
    "        #     smote=BorderlineSMOTE(random_state=27,k_neighbors=5)\n",
    "        #     smote_x_train,smote_y_train=smote.fit_resample(self.x_train,self.movie_train[label])\n",
    "        #     print('... Processing {}'.format(label))\n",
    "\n",
    "        #     logreg.fit(smote_x_train, smote_y_train)\n",
    "        #     logreg_list.append(logreg)\n",
    "        #     y_pred_X = logreg.predict(smote_x_train)\n",
    "        #     print('Training accuracy is {}'.format(f1_score(smote_y_train, y_pred_X)))\n",
    "\n",
    "        \n",
    "        # with open('./trained_model_params/log_borderlineSMOTEmodelByTitle.pkl','wb') as file:\n",
    "        #     pickle.dump(logreg_list,file)\n",
    "\n",
    "        #Logistic Regression with SMOTEENN algorithm \n",
    "        # logreg_list.clear()\n",
    "        # for label in param_rating.genre2idx.keys():\n",
    "        #     logreg = LogisticRegression(C=1.44)\n",
    "        #     smote=SMOTEENN(random_state=27)\n",
    "        #     smote_x_train,smote_y_train=smote.fit_resample(self.x_train,self.movie_train[label])\n",
    "        #     print('... Processing {}'.format(label))\n",
    "\n",
    "        #     logreg.fit(smote_x_train, smote_y_train)\n",
    "        #     logreg_list.append(logreg)\n",
    "        #     y_pred_X = logreg.predict(smote_x_train)\n",
    "        #     print('Training accuracy is {}'.format(f1_score(smote_y_train, y_pred_X)))\n",
    "        # with open('./trained_model_params/log_borderlineSMOTEENNmodelByTitle.pkl','wb') as file:\n",
    "        #     pickle.dump(logreg_list,file)\n",
    "        \n",
    "        #Gradient Boosting\n",
    "        # logreg_list.clear()\n",
    "        # for label in param_rating.genre2idx.keys():\n",
    "        #     logreg = XGBClassifier(max_depth=6, learning_rate=1e-2) \n",
    "        #     smote=SMOTEENN(random_state=27)\n",
    "        #     smote_x_train,smote_y_train=smote.fit_resample(self.x_train,self.movie_train[label])\n",
    "        #     print('... Processing {}'.format(label))\n",
    "        #     X_train, X_validation, Y_train, Y_validation = train_test_split(smote_x_train, \n",
    "        #                                                       smote_y_train, \n",
    "        #                                                       test_size=0.25)\n",
    "        #     logreg.fit(X_train, Y_train, eval_metric=\"logloss\", eval_set=[(X_validation, Y_validation)], early_stopping_rounds=10, verbose=True)\n",
    "            \n",
    "        #     logreg_list.append(logreg)\n",
    "        #     y_pred_X = logreg.predict(smote_x_train)\n",
    "        #     print('Training accuracy is {}'.format(f1_score(smote_y_train, y_pred_X)))\n",
    "        # with open('./trained_model_params/gradientboostingbytitle.pkl','wb') as file:\n",
    "        #     pickle.dump(logreg_list,file)\n",
    "\n",
    "        #Neural network\n",
    "        model = models.Sequential([\n",
    "            layers.Dense(512, activation='relu', input_shape=(self.x_train.shape[1],)),\n",
    "            layers.Dropout(0.8),\n",
    "            layers.Dense(300, activation='relu'),\n",
    "            layers.Dropout(0.8),\n",
    "            layers.Dense(len(param_rating.genre2idx), activation='sigmoid')  # Use 'sigmoid' for multi-label classification\n",
    "        ])\n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc',neural_metrics.f1_m,neural_metrics.precision_m, neural_metrics.recall_m])\n",
    "        model.fit(\n",
    "            self.x_train, self.y_train,\n",
    "            epochs=50,  \n",
    "            batch_size=200\n",
    "        )\n",
    "        model.save('./trained_model_params/neuralbytitle.h5')\n",
    "        # with open('./trained_model_params/neuralbytitle.pkl','wb') as file:\n",
    "        #     pickle.dump(model,file)\n",
    "\n",
    "        #SVM\n",
    "            \n",
    "        # svm_model=SVC(kernel='rbf', C=0.01, gamma=0.5385, probability=True)\n",
    "        # multilabel_classifier = MultiOutputClassifier(svm_model, n_jobs=-1)\n",
    "        # multilabel_classifier = multilabel_classifier.fit(self.x_train, self.y_train)\n",
    "        # with open('./trained_model_params/svm_modelByTitle.pkl', 'wb') as file:\n",
    "        #     pickle.dump(multilabel_classifier, file)\n",
    "        \n",
    "        \n",
    "        #Classifier Chains Technique for logistic regression\n",
    "        # logreg_list.clear()\n",
    "        # data_classifier=self.movie_train.copy()\n",
    "        # x_train_classfier=self.x_train.copy()\n",
    "        # for label in param_rating.genre2idx.keys():\n",
    "        #     logreg_classifier = LogisticRegression(C=1.44)\n",
    "        #     print('... Processing {}'.format(label))\n",
    "        #     y = data_classifier[label]\n",
    "        #     logreg_classifier.fit(x_train_classfier, y)\n",
    "        #     logreg_list.append(logreg_classifier)\n",
    "        #     y_pred_X = logreg_classifier.predict(x_train_classfier)\n",
    "        #     print('Training accuracy is {}'.format(f1_score(y, y_pred_X)))\n",
    "        #     x_train_classfier=self.__add_feature(x_train_classfier,y)\n",
    "        # with open('./trained_model_params/log_chainsByTitle.pkl', 'wb') as file:\n",
    "        #     pickle.dump(logreg_list, file)\n",
    "\n",
    "    def __add_feature(self,X, feature_to_add):\n",
    "            return hstack([X, csr_matrix(feature_to_add).T], 'csr')\n",
    "    \n",
    "    def predict(self,movie_test):\n",
    "        self.__preprocess_data_test(movie_test)\n",
    "        log_smote=pickle.load(open('./trained_model_params/log_borderlineSMOTEmodelByTitle.pkl', 'rb'))\n",
    "        log_smoteenn=pickle.load(open('./trained_model_params/log_borderlineSMOTEENNmodelByTitle.pkl', 'rb'))\n",
    "        boosting=pickle.load(open('./trained_model_params/gradientboostingbytitle.pkl', 'rb'))\n",
    "        # neural=pickle.load(open('./trained_model_params/neuralbytitle.pkl', 'rb'))\n",
    "        neural=load_model('./trained_model_params/neuralbytitle.h5', custom_objects={'f1_m': neural_metrics.f1_m, \n",
    "                                                               'precision_m': neural_metrics.precision_m, \n",
    "                                                               'recall_m': neural_metrics.recall_m})\n",
    "        svm=pickle.load(open('./trained_model_params/svm_modelByTitle.pkl', 'rb'))\n",
    "        log_chains=pickle.load(open('./trained_model_params/log_chainsByTitle.pkl', 'rb'))\n",
    "        submission_binary = pd.DataFrame(columns=param_rating.genre2idx.keys())\n",
    "        submission_binary_combined = pd.DataFrame(columns=param_rating.genre2idx.keys())\n",
    "        submission_boost = pd.DataFrame(columns=param_rating.genre2idx.keys())\n",
    "        submission_svm = pd.DataFrame(columns=param_rating.genre2idx.keys())\n",
    "        submission_chains = pd.DataFrame(columns=param_rating.genre2idx.keys())\n",
    "        #Logistic Regression with BorderlineSMOTE algorithm\n",
    "        for label in param_rating.genre2idx.keys():\n",
    "            test_y_prob = log_smoteenn[param_rating.genre2idx[label]].predict_proba(self.x_test)[:,1]\n",
    "            submission_binary[label] = test_y_prob\n",
    "        #Logistic Regression with SMOTEENN algorithm \n",
    "        for label in param_rating.genre2idx.keys():\n",
    "            test_y_prob = log_smote[param_rating.genre2idx[label]].predict_proba(self.x_test)[:,1]\n",
    "            submission_binary_combined[label] = test_y_prob\n",
    "        #Gradient Boosting    \n",
    "        for label in param_rating.genre2idx.keys():\n",
    "            test_y_prob = boosting[param_rating.genre2idx[label]].predict_proba(self.x_test)[:,1]\n",
    "            submission_boost[label] = test_y_prob\n",
    "        #Neural network\n",
    "        submission_neural = neural.predict(self.x_test)\n",
    "        self.test_neural=submission_neural\n",
    "        #SVM\n",
    "        y_test_pred = svm.predict_proba(self.x_test)\n",
    "        y_test_pred_svm=np.array(y_test_pred.copy())\n",
    "        submission_svm = pd.DataFrame(columns=param_rating.genre2idx.keys())\n",
    "        for label in param_rating.genre2idx.keys():\n",
    "            submission_svm[label]=y_test_pred_svm[param_rating.genre2idx[label]][:,1]\n",
    "        #Classifier Chains Technique for logistic regression\n",
    "        x_test_classfier=self.x_test.copy()\n",
    "        for label in param_rating.genre2idx.keys():\n",
    "            test_y = log_chains[param_rating.genre2idx[label]].predict(x_test_classfier)\n",
    "            test_y_prob = log_chains[param_rating.genre2idx[label]].predict_proba(x_test_classfier)[:,1]\n",
    "            submission_chains[label] = test_y_prob\n",
    "            x_test_classfier = self.__add_feature(x_test_classfier, test_y)\n",
    "        self.submission_combined=(submission_binary_combined[param_rating.genre2idx.keys()]+submission_binary[param_rating.genre2idx.keys()]+submission_boost[param_rating.genre2idx.keys()]+submission_neural\n",
    "                     +submission_chains[param_rating.genre2idx.keys()]+submission_svm[param_rating.genre2idx.keys()])/6\n",
    "    def get_column_names(self,row):\n",
    "        return list(self.vectors_labels.columns[row == 1])\n",
    "    def evaluate_model(self):\n",
    "        self.vectors_labels=pd.DataFrame(np.array(self.movie_test[param_rating.genre2idx.keys()]))\n",
    "        sorted_prediction_ids = np.argsort(-self.submission_combined,axis=1)\n",
    "        top_5_prediction_ids = sorted_prediction_ids[:,:5]\n",
    "        vectors_labels_test_new=self.vectors_labels.apply(self.get_column_names,axis=1).tolist()\n",
    "        print(map_at_k.mapk(vectors_labels_test_new,top_5_prediction_ids,k=5))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 2ms/step\n",
      "0.5557553982553982\n"
     ]
    }
   ],
   "source": [
    "model2=ModelByTitle(movies_train)\n",
    "model2.preprocess_data()\n",
    "model2.predict(movies_test)\n",
    "model2.evaluate_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add image path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For movie-train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_train.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For movie test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "movies_test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = text.lower()\n",
    "    tokens = wordpunct_tokenize(text)\n",
    "    tokens = tokens[:-1] # remove last token because it is the year which maybe is not useful\n",
    "    return tokens\n",
    "def create_vocab():\n",
    "    df = movies_train.copy()\n",
    "    arr_title = df['title'].tolist()\n",
    "    vocab = set()\n",
    "    for title in arr_title:\n",
    "        tokens = tokenize(title)\n",
    "        vocab.update(tokens)\n",
    "    vocab = list(vocab)\n",
    "    pad_token = '<PAD>'\n",
    "    unk_token = '<UNK>'\n",
    "    vocab.append(pad_token)\n",
    "    vocab.append(unk_token)\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check whether some of examples are null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop id column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_train=movies_train.drop(\"id\",axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_test=movies_test.drop(\"id\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = create_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieid</th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1650</td>\n",
       "      <td>Washington Square (1997)</td>\n",
       "      <td>[Drama]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>185</td>\n",
       "      <td>Net, The (1995)</td>\n",
       "      <td>[Sci-Fi, Thriller]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1377</td>\n",
       "      <td>Batman Returns (1992)</td>\n",
       "      <td>[Action, Adventure, Comedy, Crime]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3204</td>\n",
       "      <td>Boys from Brazil, The (1978)</td>\n",
       "      <td>[Thriller]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1901</td>\n",
       "      <td>Dear Jesse (1997)</td>\n",
       "      <td>[Documentary]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3101</th>\n",
       "      <td>2539</td>\n",
       "      <td>Analyze This (1999)</td>\n",
       "      <td>[Comedy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3102</th>\n",
       "      <td>3038</td>\n",
       "      <td>Face in the Crowd, A (1957)</td>\n",
       "      <td>[Drama]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3103</th>\n",
       "      <td>1832</td>\n",
       "      <td>Heaven's Burning (1997)</td>\n",
       "      <td>[Action, Drama]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3104</th>\n",
       "      <td>657</td>\n",
       "      <td>Yankee Zulu (1994)</td>\n",
       "      <td>[Comedy, Drama]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3105</th>\n",
       "      <td>1750</td>\n",
       "      <td>Star Kid (1997)</td>\n",
       "      <td>[Adventure, Children's, Fantasy, Sci-Fi]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3106 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      movieid                         title  \\\n",
       "0        1650      Washington Square (1997)   \n",
       "1         185               Net, The (1995)   \n",
       "2        1377         Batman Returns (1992)   \n",
       "3        3204  Boys from Brazil, The (1978)   \n",
       "4        1901             Dear Jesse (1997)   \n",
       "...       ...                           ...   \n",
       "3101     2539           Analyze This (1999)   \n",
       "3102     3038   Face in the Crowd, A (1957)   \n",
       "3103     1832       Heaven's Burning (1997)   \n",
       "3104      657            Yankee Zulu (1994)   \n",
       "3105     1750               Star Kid (1997)   \n",
       "\n",
       "                                         genre  \n",
       "0                                      [Drama]  \n",
       "1                           [Sci-Fi, Thriller]  \n",
       "2           [Action, Adventure, Comedy, Crime]  \n",
       "3                                   [Thriller]  \n",
       "4                                [Documentary]  \n",
       "...                                        ...  \n",
       "3101                                  [Comedy]  \n",
       "3102                                   [Drama]  \n",
       "3103                           [Action, Drama]  \n",
       "3104                           [Comedy, Drama]  \n",
       "3105  [Adventure, Children's, Fantasy, Sci-Fi]  \n",
       "\n",
       "[3106 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PreProcess Title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movie train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =  movies_train.copy()\n",
    "data['title_tokens'] = [tokenize(x) for x in data.title]\n",
    "# create vocab\n",
    "pad_token = '<PAD>'\n",
    "unk_token = '<UNK>'\n",
    "token2idx = {token: idx for idx, token in enumerate(vocab)}\n",
    "# Create a binary vector for each word in each sentence\n",
    "MAX_LENGTH = 7\n",
    "vectors = []\n",
    "for title_tokens in data.title_tokens.tolist():\n",
    "    if len(title_tokens) < MAX_LENGTH:\n",
    "        num_pad = MAX_LENGTH - len(title_tokens)\n",
    "        for idx in range(num_pad):\n",
    "            title_tokens.append(pad_token)\n",
    "    else:\n",
    "        title_tokens = title_tokens[:MAX_LENGTH]\n",
    "    title_vectors = np.zeros(len(vocab))\n",
    "    for word in title_tokens:\n",
    "        if word in vocab:\n",
    "            title_vectors[token2idx[word]] = 1\n",
    "        else:\n",
    "            title_vectors[token2idx[unk_token]] = 1\n",
    "\n",
    "    vectors.append(np.array(title_vectors))\n",
    "data['vectors'] = vectors \n",
    "# data['vectors'][0].shape #→7x3899"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0., 0., 0., ..., 0., 1., 0.])]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['movieid']==3204]['vectors'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movie test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test =  movies_test.copy()\n",
    "data_test['title_tokens'] = [tokenize(x) for x in data_test.title]\n",
    "# create vocab\n",
    "pad_token = '<PAD>'\n",
    "unk_token = '<UNK>'\n",
    "token2idx = {token: idx for idx, token in enumerate(vocab)}\n",
    "# Create a binary vector for each word in each sentence\n",
    "MAX_LENGTH = 7\n",
    "vectors = []\n",
    "for title_tokens in data_test.title_tokens.tolist():\n",
    "    if len(title_tokens) < MAX_LENGTH:\n",
    "        num_pad = MAX_LENGTH - len(title_tokens)\n",
    "        for idx in range(num_pad):\n",
    "            title_tokens.append(pad_token)\n",
    "    else:\n",
    "        title_tokens = title_tokens[:MAX_LENGTH]\n",
    "    title_vectors = np.zeros(len(vocab))\n",
    "    for word in title_tokens:\n",
    "        if word in vocab:\n",
    "            title_vectors[token2idx[word]] = 1\n",
    "        else:\n",
    "            title_vectors[token2idx[unk_token]] = 1\n",
    "\n",
    "    vectors.append(np.array(title_vectors))\n",
    "data_test['vectors'] = vectors \n",
    "# data['vectors'][0].shape #→7x3899"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PreProcess Label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label genre\n",
    "with open('./dataset/genres.txt', 'r') as f:\n",
    "    genre_all = f.readlines()\n",
    "    genre_all = [x.replace('\\n','') for x in genre_all]\n",
    "genre2idx = {genre:idx for idx, genre in enumerate(genre_all)}\n",
    "vectors_genre=[]\n",
    "for genre in data.genre.tolist():\n",
    "    genre_vector = np.zeros(len(genre2idx))\n",
    "    for g in genre:\n",
    "        genre_vector[genre2idx[g]] = 1\n",
    "    vectors_genre.append(genre_vector)\n",
    "data['genre_vectors']=vectors_genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "1       [0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "2       [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...\n",
       "3       [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "4       [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...\n",
       "                              ...                        \n",
       "3101    [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...\n",
       "3102    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "3103    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "3104    [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...\n",
       "3105    [0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, ...\n",
       "Name: genre_vectors, Length: 3106, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['genre_vectors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_df = pd.DataFrame(data['genre_vectors'].tolist(), columns=genre2idx.keys())\n",
    "data = pd.concat([data, genre_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Crime</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Western</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Action</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>War</th>\n",
       "      <th>Children's</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3101</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3102</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3103</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3104</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3105</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3106 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Crime  Thriller  Fantasy  Horror  Sci-Fi  Comedy  Documentary  \\\n",
       "0       0.0       0.0      0.0     0.0     0.0     0.0          0.0   \n",
       "1       0.0       1.0      0.0     0.0     1.0     0.0          0.0   \n",
       "2       1.0       0.0      0.0     0.0     0.0     1.0          0.0   \n",
       "3       0.0       1.0      0.0     0.0     0.0     0.0          0.0   \n",
       "4       0.0       0.0      0.0     0.0     0.0     0.0          1.0   \n",
       "...     ...       ...      ...     ...     ...     ...          ...   \n",
       "3101    0.0       0.0      0.0     0.0     0.0     1.0          0.0   \n",
       "3102    0.0       0.0      0.0     0.0     0.0     0.0          0.0   \n",
       "3103    0.0       0.0      0.0     0.0     0.0     0.0          0.0   \n",
       "3104    0.0       0.0      0.0     0.0     0.0     1.0          0.0   \n",
       "3105    0.0       0.0      1.0     0.0     1.0     0.0          0.0   \n",
       "\n",
       "      Adventure  Film-Noir  Animation  Romance  Drama  Western  Musical  \\\n",
       "0           0.0        0.0        0.0      0.0    1.0      0.0      0.0   \n",
       "1           0.0        0.0        0.0      0.0    0.0      0.0      0.0   \n",
       "2           1.0        0.0        0.0      0.0    0.0      0.0      0.0   \n",
       "3           0.0        0.0        0.0      0.0    0.0      0.0      0.0   \n",
       "4           0.0        0.0        0.0      0.0    0.0      0.0      0.0   \n",
       "...         ...        ...        ...      ...    ...      ...      ...   \n",
       "3101        0.0        0.0        0.0      0.0    0.0      0.0      0.0   \n",
       "3102        0.0        0.0        0.0      0.0    1.0      0.0      0.0   \n",
       "3103        0.0        0.0        0.0      0.0    1.0      0.0      0.0   \n",
       "3104        0.0        0.0        0.0      0.0    1.0      0.0      0.0   \n",
       "3105        1.0        0.0        0.0      0.0    0.0      0.0      0.0   \n",
       "\n",
       "      Action  Mystery  War  Children's  \n",
       "0        0.0      0.0  0.0         0.0  \n",
       "1        0.0      0.0  0.0         0.0  \n",
       "2        1.0      0.0  0.0         0.0  \n",
       "3        0.0      0.0  0.0         0.0  \n",
       "4        0.0      0.0  0.0         0.0  \n",
       "...      ...      ...  ...         ...  \n",
       "3101     0.0      0.0  0.0         0.0  \n",
       "3102     0.0      0.0  0.0         0.0  \n",
       "3103     1.0      0.0  0.0         0.0  \n",
       "3104     0.0      0.0  0.0         0.0  \n",
       "3105     0.0      0.0  0.0         1.0  \n",
       "\n",
       "[3106 rows x 18 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[genre2idx.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop('genre_vectors',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "data[genre2idx.keys()].sum().plot(kind='bar', color='skyblue')\n",
    "plt.title('Genre Counts')\n",
    "plt.xlabel('Genre')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors_genre=[]\n",
    "for genre in data_test.genre.tolist():\n",
    "    genre_vector = np.zeros(len(genre2idx))\n",
    "    for g in genre:\n",
    "        genre_vector[genre2idx[g]] = 1\n",
    "    vectors_genre.append(genre_vector)\n",
    "data_test['genre_vectors']=vectors_genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_test = pd.DataFrame(data_test['genre_vectors'].tolist(), columns=genre2idx.keys())\n",
    "data_test = pd.concat([data_test, genre_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test=data_test.drop('genre_vectors',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=np.expand_dims(data['vectors'], 0)\n",
    "x_train=np.vstack(np.ravel(np.ravel(x_train))) \n",
    "y_train=np.expand_dims(data['genre_vectors'], 0)\n",
    "y_train=np.vstack(np.ravel(np.ravel(y_train))) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Crime\n",
       "0.0    2926\n",
       "1.0    2926\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# smote_y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=np.expand_dims(data_test['vectors'], 0)\n",
    "x_test=np.vstack(np.ravel(np.ravel(x_test))) \n",
    "y_test=np.expand_dims(data_test['genre_vectors'], 0)\n",
    "y_test=np.vstack(np.ravel(np.ravel(y_test))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>777 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2    3    4    5    6    7    8    9    10   11   12   13  \\\n",
       "0    0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0   \n",
       "2    0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0   \n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "772  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0   \n",
       "773  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0   \n",
       "774  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0   \n",
       "775  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0   \n",
       "776  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "      14   15   16   17  \n",
       "0    0.0  0.0  0.0  1.0  \n",
       "1    0.0  0.0  1.0  0.0  \n",
       "2    0.0  0.0  0.0  0.0  \n",
       "3    1.0  0.0  0.0  0.0  \n",
       "4    0.0  0.0  0.0  0.0  \n",
       "..   ...  ...  ...  ...  \n",
       "772  0.0  0.0  0.0  0.0  \n",
       "773  1.0  0.0  0.0  0.0  \n",
       "774  0.0  0.0  0.0  0.0  \n",
       "775  0.0  0.0  0.0  0.0  \n",
       "776  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[777 rows x 18 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "from sklearn.svm import SVC\n",
    "from metric3 import map_atk , guess_genre\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optunity\n",
    "import optunity.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import SMOTE,BorderlineSMOTE,ADASYN\n",
    "from imblearn.combine import SMOTEENN\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=data[\"Crime\"]\n",
    "def internal_method_logisitic(C):\n",
    "\n",
    "    model = LogisticRegression(C = C)\n",
    "\n",
    "    return cross_val_score(model, smote_x_train, smote_y_train, cv=10, scoring='f1').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_bayes = {'C': (1e-5,2) }\n",
    "optimizer = BayesianOptimization(f = internal_method_logisitic,\n",
    "                                pbounds = params_bayes,\n",
    "                                random_state = 7,\n",
    "\t\t\t\t                verbose=2,\n",
    "                                allow_duplicate_points=True)\n",
    "optimizer.maximize(init_points=2, n_iter=20)\n",
    "optimal_params = optimizer.max['params']\n",
    "optimal_C = optimal_params['C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Processing Crime\n",
      "Training accuracy is 0.9965870307167235\n"
     ]
    }
   ],
   "source": [
    "# logreg = LogisticRegression(C=2.0) #LogisticRegression(C=1.44)\n",
    "# print('... Processing {}'.format(\"Crime\"))\n",
    "# y = smote_y_train\n",
    "# # train the model using X_dtm & y\n",
    "# logreg.fit(smote_x_train, y)\n",
    "# # compute the training accuracy\n",
    "# y_pred_X = logreg.predict(smote_x_train)\n",
    "# print('Training accuracy is {}'.format(f1_score(y, y_pred_X)))\n",
    "# # compute the predicted probabilities for X_test_dtm\n",
    "# test_y_prob = logreg.predict_proba(x_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1111111111111111, 0.6810000000000005)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# threshold=0.01\n",
    "# maxvalue=0\n",
    "# bestT=0\n",
    "# for t in range(990):\n",
    "#     test_y_prob_new=(test_y_prob>=threshold).astype(int)\n",
    "#     tempval=f1_score(data_test[\"Crime\"],test_y_prob_new)\n",
    "#     if maxvalue< tempval:\n",
    "#         maxvalue=tempval\n",
    "#         bestT=threshold\n",
    "#     threshold+=0.001\n",
    "# maxvalue,bestT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote=SMOTEENN(random_state=27)\n",
    "smote_x_train,smote_y_train=smote.fit_resample(x_train,data[\"Crime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Crime\n",
       "1.0    2913\n",
       "0.0     618\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smote_y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import and instantiate the Logistic Regression model\n",
    "#  #LogisticRegression(C=1.44)\n",
    "# submission_binary = pd.read_csv('submission.csv')\n",
    "# model_rating=[]\n",
    "# hype_param_best=[]\n",
    "# for label in genre2idx.keys():\n",
    "#     logreg = LogisticRegression(C=0.05)\n",
    "#     smote=BorderlineSMOTE(random_state=27,k_neighbors=5)\n",
    "#     smote_x_train,smote_y_train=smote.fit_resample(x_train,data[label])\n",
    "#     print('... Processing {}'.format(label))\n",
    "#     # train the model using X_dtm & y\n",
    "#     logreg.fit(smote_x_train, smote_y_train)\n",
    "#     # compute the training accuracy\n",
    "#     model_rating.append(logreg)\n",
    "#     y_pred_X = logreg.predict_proba(smote_x_train)[:,:1]\n",
    "#     y_pred_X1 = logreg.predict(smote_x_train)\n",
    "#     print('Training accuracy(before) is {}'.format(f1_score(smote_y_train, y_pred_X1)))\n",
    "#     hype_param=0\n",
    "#     interval=0.01\n",
    "#     maxScore=0\n",
    "#     for _ in range(990):\n",
    "#         interval+=0.001\n",
    "#         y_pred_new=(y_pred_X>=interval).astype(int)\n",
    "#         temp_score=f1_score(smote_y_train,y_pred_new)\n",
    "#         if temp_score>maxScore:\n",
    "#             maxScore=temp_score\n",
    "#             hype_param=interval\n",
    "#     print(f\"{label}: maxScore: {maxScore} best T:{hype_param}\")\n",
    "\n",
    "#     hype_param_best.append(hype_param)\n",
    "\n",
    "#     print('Training accuracy(after) is {}'.format(f1_score(smote_y_train, (y_pred_X>=hype_param).astype(int))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apk(actual, predicted, k=10):\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(actual, predicted, k=10):\n",
    "    return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors_labels=pd.DataFrame(np.array(data_test[genre2idx.keys()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'./model_class')\n",
    "from bert_model import BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(777, 18)\n"
     ]
    }
   ],
   "source": [
    "datasub=pd.DataFrame(pd.read_csv('./cleaned_data/movies_test.csv'))\n",
    "# test = pd.read_csv('origin_data\\movies_test.dat', engine='python',\n",
    "#                      sep='::', names=['movieid', 'title', 'genre'], encoding='latin-1', index_col=False)\n",
    "weight_path = 'weight\\model-fine-tune2.pth'\n",
    "model = BertModel(weight_path, max_len= 7)\n",
    "# if os.path.exists(weight_path):\n",
    "#     print('afasdf')\n",
    "res = model.predict(datasub)\n",
    "print(np.array(res).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Crime',\n",
       " 1: 'Thriller',\n",
       " 2: 'Fantasy',\n",
       " 3: 'Horror',\n",
       " 4: 'Sci-Fi',\n",
       " 5: 'Comedy',\n",
       " 6: 'Documentary',\n",
       " 7: 'Adventure',\n",
       " 8: 'Film-Noir',\n",
       " 9: 'Animation',\n",
       " 10: 'Romance',\n",
       " 11: 'Drama',\n",
       " 12: 'Western',\n",
       " 13: 'Musical',\n",
       " 14: 'Action',\n",
       " 15: 'Mystery',\n",
       " 16: 'War',\n",
       " 17: \"Children's\"}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dict=dict([(value,key) for key,value in genre2idx.items()])\n",
    "new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.rename(columns=new_dict,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37268447018447015"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_prediction__trainids = np.argsort(-res,axis=1)\n",
    "top_10_prediction_trainids = sorted_prediction__trainids[:,:5]\n",
    "def get_column_names_train(row):\n",
    "    return list(vectors_labels.columns[row == 1])\n",
    "vectors_labels_new=vectors_labels.apply(get_column_names_train,axis=1).tolist()\n",
    "mapk(vectors_labels_new,top_10_prediction_trainids,k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BorderlineSMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and instantiate the Logistic Regression model\n",
    "logreg = LogisticRegression(C=1.56) #LogisticRegression(C=1.44)\n",
    "submission_binary = pd.DataFrame(columns=genre2idx.keys())\n",
    "for label in genre2idx.keys():\n",
    "    smote=BorderlineSMOTE(random_state=27,k_neighbors=5)\n",
    "    smote_x_train,smote_y_train=smote.fit_resample(x_train,data[label])\n",
    "    print('... Processing {}'.format(label))\n",
    "    # train the model using X_dtm & y\n",
    "    logreg.fit(smote_x_train, smote_y_train)\n",
    "    # compute the training accuracy\n",
    "    y_pred_X = logreg.predict(smote_x_train)\n",
    "    print('Training accuracy is {}'.format(f1_score(smote_y_train, y_pred_X)))\n",
    "    # compute the predicted probabilities for X_test_dtm\n",
    "    test_y_prob = logreg.predict_proba(x_test)[:,1]\n",
    "    submission_binary[label] = test_y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy is 0.07673267326732673\n",
      "Training accuracy is 0.24009060022650056\n",
      "Training accuracy is 0.01785714285714286\n",
      "Training accuracy is 0.176056338028169\n",
      "Training accuracy is 0.11636363636363635\n",
      "Training accuracy is 0.48242187500000006\n",
      "Training accuracy is 0.07434944237918216\n",
      "Training accuracy is 0.11636363636363635\n",
      "Training accuracy is 0.015325670498084292\n",
      "Training accuracy is 0.052631578947368425\n",
      "Training accuracy is 0.21584385763490244\n",
      "Training accuracy is 0.569060773480663\n",
      "Training accuracy is 0.035398230088495575\n",
      "Training accuracy is 0.03291139240506329\n",
      "Training accuracy is 0.20761245674740486\n",
      "Training accuracy is 0.045283018867924525\n",
      "Training accuracy is 0.062344139650872814\n",
      "Training accuracy is 0.11636363636363635\n"
     ]
    }
   ],
   "source": [
    "for label in genre2idx.keys():\n",
    "    y_pred_X = model_rating[genre2idx[label]].predict_proba(x_test)[:,:1]\n",
    "    submission_binary[label]=y_pred_X\n",
    "    print('Training accuracy is {}'.format(f1_score(data_test[label], (y_pred_X>=hype_param_best[genre2idx[label]]).astype(int))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>777 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2    3    4    5    6    7    8    9    10   11   12   13  \\\n",
       "0    0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0   \n",
       "2    0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0   \n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "772  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0   \n",
       "773  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0   \n",
       "774  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0   \n",
       "775  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0   \n",
       "776  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "      14   15   16   17  \n",
       "0    0.0  0.0  0.0  1.0  \n",
       "1    0.0  0.0  1.0  0.0  \n",
       "2    0.0  0.0  0.0  0.0  \n",
       "3    1.0  0.0  0.0  0.0  \n",
       "4    0.0  0.0  0.0  0.0  \n",
       "..   ...  ...  ...  ...  \n",
       "772  0.0  0.0  0.0  0.0  \n",
       "773  1.0  0.0  0.0  0.0  \n",
       "774  0.0  0.0  0.0  0.0  \n",
       "775  0.0  0.0  0.0  0.0  \n",
       "776  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[777 rows x 18 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.array(data_test[genre2idx.keys()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5411786786786786"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_prediction__trainids = np.argsort(-submission_binary[genre2idx.keys()],axis=1)\n",
    "top_10_prediction_trainids = sorted_prediction__trainids[:,:5]\n",
    "def get_column_names_train(row):\n",
    "    return list(vectors_labels.columns[row == 1])\n",
    "vectors_labels_new=vectors_labels.apply(get_column_names_train,axis=1).tolist()\n",
    "mapk(vectors_labels_new,top_10_prediction_trainids,k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4277534523408555, 0.2970000000000002)"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions=np.array(submission_binary[genre2idx.keys()])\n",
    "threshold=0.01\n",
    "maxvalue=0\n",
    "bestT=0\n",
    "for t in range(990):\n",
    "    predictions_new=(predictions>=threshold).astype(int)\n",
    "    tempval=f1_score(y_test,predictions_new,average=\"micro\")\n",
    "    if maxvalue< tempval:\n",
    "        maxvalue=tempval\n",
    "        bestT=threshold\n",
    "    threshold+=0.001\n",
    "maxvalue,bestT\n",
    "# map_atk(y_test,predictions,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(C=1.44) #LogisticRegression(C=1.44)\n",
    "submission_binary_combined = pd.DataFrame(columns=genre2idx.keys())\n",
    "for label in genre2idx.keys():\n",
    "    smote=SMOTEENN(random_state=27)\n",
    "    smote_x_train,smote_y_train=smote.fit_resample(x_train,data[label])\n",
    "    print('... Processing {}'.format(label))\n",
    "    # train the model using X_dtm & y\n",
    "    logreg.fit(smote_x_train, smote_y_train)\n",
    "    # compute the training accuracy\n",
    "    y_pred_X = logreg.predict(smote_x_train)\n",
    "    print('Training accuracy is {}'.format(f1_score(smote_y_train, y_pred_X)))\n",
    "    # compute the predicted probabilities for X_test_dtm\n",
    "    test_y_prob = logreg.predict_proba(x_test)[:,1]\n",
    "    submission_binary_combined[label] = test_y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_binary_combined[genre2idx.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5057546832546833"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_prediction__trainids = np.argsort(-submission_binary_combined[genre2idx.keys()],axis=1)\n",
    "top_10_prediction_trainids = sorted_prediction__trainids[:,:5]\n",
    "def get_column_names_train(row):\n",
    "    return list(vectors_labels.columns[row == 1])\n",
    "vectors_labels_new=vectors_labels.apply(get_column_names_train,axis=1).tolist()\n",
    "mapk(vectors_labels_new,top_10_prediction_trainids,k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = XGBClassifier(max_depth=6, learning_rate=1e-2) #LogisticRegression(C=1.44)\n",
    "submission_boost = pd.DataFrame(columns=genre2idx.keys())\n",
    "for label in genre2idx.keys():\n",
    "    smote=SMOTEENN(random_state=27)\n",
    "    smote_x_train,smote_y_train=smote.fit_resample(x_train,data[label])\n",
    "    print('... Processing {}'.format(label))\n",
    "    # train the model using X_dtm & y\n",
    "    X_train, X_validation, Y_train, Y_validation = train_test_split(smote_x_train, \n",
    "                                                              smote_y_train, \n",
    "                                                              test_size=0.25)\n",
    "    logreg.fit(X_train, Y_train, eval_metric=\"logloss\", eval_set=[(X_validation, Y_validation)], early_stopping_rounds=10, verbose=True)\n",
    "    # compute the training accuracy\n",
    "    y_pred_X = logreg.predict(smote_x_train)\n",
    "    print('Training accuracy is {}'.format(f1_score(smote_y_train, y_pred_X)))\n",
    "    # compute the predicted probabilities for X_test_dtm\n",
    "    test_y_prob = logreg.predict_proba(x_test)[:,1]\n",
    "    submission_boost[label] = test_y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4512844987844987"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_boost[genre2idx.keys()]\n",
    "sorted_prediction__trainids = np.argsort(-submission_boost[genre2idx.keys()],axis=1)\n",
    "top_10_prediction_trainids = sorted_prediction__trainids[:,:5]\n",
    "def get_column_names_train(row):\n",
    "    return list(vectors_labels.columns[row == 1])\n",
    "vectors_labels_new=vectors_labels.apply(get_column_names_train,axis=1).tolist()\n",
    "mapk(vectors_labels_new,top_10_prediction_trainids,k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.37435284747112707, 0.8630000000000007)"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions=np.array(submission_boost[genre2idx.keys()])\n",
    "threshold=0.01\n",
    "maxvalue=0\n",
    "bestT=0\n",
    "for t in range(990):\n",
    "    predictions_new=(predictions>=threshold).astype(int)\n",
    "    tempval=f1_score(y_test,predictions_new,average=\"micro\")\n",
    "    if maxvalue< tempval:\n",
    "        maxvalue=tempval\n",
    "        bestT=threshold\n",
    "    threshold+=0.001\n",
    "maxvalue,bestT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:From c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "16/16 [==============================] - 1s 22ms/step - loss: 0.5809 - acc: 0.1108 - f1_m: 0.1631 - precision_m: 0.1564 - recall_m: 0.2401\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.3324 - acc: 0.2147 - f1_m: 0.1438 - precision_m: 0.3624 - recall_m: 0.0901\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.2990 - acc: 0.2527 - f1_m: 0.1861 - precision_m: 0.3520 - recall_m: 0.1269\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.2859 - acc: 0.2373 - f1_m: 0.1552 - precision_m: 0.3750 - recall_m: 0.0985\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.2771 - acc: 0.2498 - f1_m: 0.1421 - precision_m: 0.3832 - recall_m: 0.0874\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.2705 - acc: 0.2627 - f1_m: 0.1573 - precision_m: 0.4088 - recall_m: 0.0978\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.2633 - acc: 0.2656 - f1_m: 0.1528 - precision_m: 0.4267 - recall_m: 0.0932\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.2594 - acc: 0.2682 - f1_m: 0.1470 - precision_m: 0.4563 - recall_m: 0.0878\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.2553 - acc: 0.2775 - f1_m: 0.1769 - precision_m: 0.4866 - recall_m: 0.1082\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.2516 - acc: 0.2785 - f1_m: 0.1730 - precision_m: 0.4854 - recall_m: 0.1055\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.2476 - acc: 0.2965 - f1_m: 0.1760 - precision_m: 0.5327 - recall_m: 0.1056\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.2448 - acc: 0.2885 - f1_m: 0.2029 - precision_m: 0.5253 - recall_m: 0.1260\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.2398 - acc: 0.3104 - f1_m: 0.1957 - precision_m: 0.5724 - recall_m: 0.1184\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.2358 - acc: 0.3229 - f1_m: 0.2525 - precision_m: 0.6030 - recall_m: 0.1599\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.2306 - acc: 0.3455 - f1_m: 0.2663 - precision_m: 0.6385 - recall_m: 0.1687\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.2233 - acc: 0.3735 - f1_m: 0.3048 - precision_m: 0.6861 - recall_m: 0.1965\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.2176 - acc: 0.3947 - f1_m: 0.3338 - precision_m: 0.6908 - recall_m: 0.2204\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.2117 - acc: 0.4285 - f1_m: 0.3753 - precision_m: 0.7503 - recall_m: 0.2512\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.2052 - acc: 0.4485 - f1_m: 0.3999 - precision_m: 0.7639 - recall_m: 0.2717\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.1971 - acc: 0.4855 - f1_m: 0.4460 - precision_m: 0.7980 - recall_m: 0.3098\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.1902 - acc: 0.4942 - f1_m: 0.4758 - precision_m: 0.8141 - recall_m: 0.3368\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.1830 - acc: 0.5109 - f1_m: 0.4987 - precision_m: 0.8077 - recall_m: 0.3612\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.1770 - acc: 0.5203 - f1_m: 0.5169 - precision_m: 0.8244 - recall_m: 0.3769\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.1695 - acc: 0.5344 - f1_m: 0.5388 - precision_m: 0.8413 - recall_m: 0.3968\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.1657 - acc: 0.5373 - f1_m: 0.5659 - precision_m: 0.8338 - recall_m: 0.4289\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.1580 - acc: 0.5573 - f1_m: 0.5843 - precision_m: 0.8560 - recall_m: 0.4443\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.1540 - acc: 0.5615 - f1_m: 0.5948 - precision_m: 0.8501 - recall_m: 0.4580\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.1482 - acc: 0.5802 - f1_m: 0.6222 - precision_m: 0.8523 - recall_m: 0.4905\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.1444 - acc: 0.5795 - f1_m: 0.6316 - precision_m: 0.8637 - recall_m: 0.4983\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.1411 - acc: 0.5892 - f1_m: 0.6392 - precision_m: 0.8605 - recall_m: 0.5092\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.1367 - acc: 0.5908 - f1_m: 0.6571 - precision_m: 0.8610 - recall_m: 0.5316\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.1327 - acc: 0.5908 - f1_m: 0.6706 - precision_m: 0.8687 - recall_m: 0.5465\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.1287 - acc: 0.6050 - f1_m: 0.6815 - precision_m: 0.8769 - recall_m: 0.5576\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.1247 - acc: 0.6075 - f1_m: 0.6980 - precision_m: 0.8612 - recall_m: 0.5874\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.1228 - acc: 0.6175 - f1_m: 0.7024 - precision_m: 0.8767 - recall_m: 0.5864\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.1198 - acc: 0.6191 - f1_m: 0.7111 - precision_m: 0.8760 - recall_m: 0.5989\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.1163 - acc: 0.6127 - f1_m: 0.7191 - precision_m: 0.8689 - recall_m: 0.6137\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.1159 - acc: 0.6355 - f1_m: 0.7184 - precision_m: 0.8704 - recall_m: 0.6121\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.1110 - acc: 0.6236 - f1_m: 0.7347 - precision_m: 0.8746 - recall_m: 0.6340\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.1101 - acc: 0.6362 - f1_m: 0.7381 - precision_m: 0.8778 - recall_m: 0.6373\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.1074 - acc: 0.6449 - f1_m: 0.7432 - precision_m: 0.8832 - recall_m: 0.6419\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.1067 - acc: 0.6381 - f1_m: 0.7431 - precision_m: 0.8717 - recall_m: 0.6479\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.1024 - acc: 0.6481 - f1_m: 0.7610 - precision_m: 0.8821 - recall_m: 0.6696\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.1007 - acc: 0.6574 - f1_m: 0.7609 - precision_m: 0.8779 - recall_m: 0.6717\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0990 - acc: 0.6484 - f1_m: 0.7692 - precision_m: 0.8796 - recall_m: 0.6837\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0977 - acc: 0.6545 - f1_m: 0.7675 - precision_m: 0.8816 - recall_m: 0.6798\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0954 - acc: 0.6578 - f1_m: 0.7729 - precision_m: 0.8806 - recall_m: 0.6893\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0944 - acc: 0.6542 - f1_m: 0.7776 - precision_m: 0.8862 - recall_m: 0.6930\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0936 - acc: 0.6545 - f1_m: 0.7798 - precision_m: 0.8849 - recall_m: 0.6974\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.0908 - acc: 0.6619 - f1_m: 0.7901 - precision_m: 0.8921 - recall_m: 0.7094\n",
      "98/98 [==============================] - 0s 1ms/step\n",
      "Training accuracy is 0.899957965531736\n",
      "25/25 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Dense(512, activation='relu', input_shape=(x_train.shape[1],)),\n",
    "    layers.Dropout(0.8),\n",
    "    layers.Dense(300, activation='relu'),\n",
    "    layers.Dropout(0.8),\n",
    "    layers.Dense(len(genre2idx), activation='sigmoid')  # Use 'sigmoid' for multi-label classification\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc',f1_m,precision_m, recall_m])\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=50,  # Adjust the number of epochs based on your specific requirements\n",
    "    batch_size=200\n",
    ")\n",
    "y_pred_train = model.predict(x_train)\n",
    "y_pred_train_binary = (y_pred_train > 0.5).astype(int)\n",
    "\n",
    "# Assuming y_pred_train_binary is in the same format as y_train (binary predictions)\n",
    "# You may need to adjust the format based on your specific output format\n",
    "\n",
    "print('Training accuracy is {}'.format(f1_score(y_train, y_pred_train_binary, average='micro')))\n",
    "y_pred_test = model.predict(x_test)\n",
    "# Make predictions on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.43085761181780874, 0.22100000000000017)"
      ]
     },
     "execution_count": 578,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions=np.array(y_pred_test).copy()\n",
    "threshold=0.01\n",
    "maxvalue=0\n",
    "bestT=0\n",
    "for t in range(990):\n",
    "    predictions_new=(predictions>=threshold).astype(int)\n",
    "    tempval=f1_score(y_test,predictions_new,average=\"micro\")\n",
    "    if maxvalue< tempval:\n",
    "        maxvalue=tempval\n",
    "        bestT=threshold\n",
    "    threshold+=0.001\n",
    "maxvalue,bestT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_neural=pd.DataFrame(y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_neural.rename(columns = new_dict, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5246332046332046"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_boost[genre2idx.keys()]\n",
    "sorted_prediction__trainids = np.argsort(-pd.DataFrame(submission_neural),axis=1)\n",
    "top_10_prediction_trainids = sorted_prediction__trainids[:,:5]\n",
    "def get_column_names_train(row):\n",
    "    return list(vectors_labels.columns[row == 1])\n",
    "vectors_labels_new=vectors_labels.apply(get_column_names_train,axis=1).tolist()\n",
    "mapk(vectors_labels_new,top_10_prediction_trainids,k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.multioutput import MultiOutputClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model=SVC(kernel='rbf', C=0.01, gamma=0.5385, probability=True)\n",
    "multilabel_classifier = MultiOutputClassifier(svm_model, n_jobs=-1)\n",
    "multilabel_classifier = multilabel_classifier.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./trained_model_params/svm_modelByTitle.pkl', 'wb') as file:\n",
    "            pickle.dump(multilabel_classifier, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = multilabel_classifier.predict_proba(x_test)\n",
    "\n",
    "# f1_score(y_test,y_test_pred,average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Crime</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Western</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Action</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>War</th>\n",
       "      <th>Children's</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.052388</td>\n",
       "      <td>0.085766</td>\n",
       "      <td>0.017553</td>\n",
       "      <td>0.047432</td>\n",
       "      <td>0.029959</td>\n",
       "      <td>0.358913</td>\n",
       "      <td>0.025432</td>\n",
       "      <td>0.132096</td>\n",
       "      <td>0.011952</td>\n",
       "      <td>0.009268</td>\n",
       "      <td>0.113822</td>\n",
       "      <td>0.368692</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>0.061539</td>\n",
       "      <td>0.081528</td>\n",
       "      <td>0.025350</td>\n",
       "      <td>0.058420</td>\n",
       "      <td>0.285543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.049774</td>\n",
       "      <td>0.110978</td>\n",
       "      <td>0.018673</td>\n",
       "      <td>0.042009</td>\n",
       "      <td>0.052269</td>\n",
       "      <td>0.298965</td>\n",
       "      <td>0.026855</td>\n",
       "      <td>0.064355</td>\n",
       "      <td>0.011464</td>\n",
       "      <td>0.024774</td>\n",
       "      <td>0.107312</td>\n",
       "      <td>0.358935</td>\n",
       "      <td>0.014587</td>\n",
       "      <td>0.031876</td>\n",
       "      <td>0.103609</td>\n",
       "      <td>0.025515</td>\n",
       "      <td>0.031971</td>\n",
       "      <td>0.045153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.048515</td>\n",
       "      <td>0.082972</td>\n",
       "      <td>0.017452</td>\n",
       "      <td>0.924401</td>\n",
       "      <td>0.051143</td>\n",
       "      <td>0.273917</td>\n",
       "      <td>0.028854</td>\n",
       "      <td>0.051483</td>\n",
       "      <td>0.019078</td>\n",
       "      <td>0.019941</td>\n",
       "      <td>0.107947</td>\n",
       "      <td>0.352339</td>\n",
       "      <td>0.008229</td>\n",
       "      <td>0.030006</td>\n",
       "      <td>0.091558</td>\n",
       "      <td>0.020953</td>\n",
       "      <td>0.035023</td>\n",
       "      <td>0.043738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.070496</td>\n",
       "      <td>0.157967</td>\n",
       "      <td>0.018502</td>\n",
       "      <td>0.052650</td>\n",
       "      <td>0.068607</td>\n",
       "      <td>0.375741</td>\n",
       "      <td>0.034541</td>\n",
       "      <td>0.082037</td>\n",
       "      <td>0.012114</td>\n",
       "      <td>0.023979</td>\n",
       "      <td>0.158922</td>\n",
       "      <td>0.396230</td>\n",
       "      <td>0.014563</td>\n",
       "      <td>0.028537</td>\n",
       "      <td>0.122983</td>\n",
       "      <td>0.054794</td>\n",
       "      <td>0.034700</td>\n",
       "      <td>0.050521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.054056</td>\n",
       "      <td>0.103110</td>\n",
       "      <td>0.018724</td>\n",
       "      <td>0.056426</td>\n",
       "      <td>0.054847</td>\n",
       "      <td>0.262357</td>\n",
       "      <td>0.030098</td>\n",
       "      <td>0.058324</td>\n",
       "      <td>0.012319</td>\n",
       "      <td>0.024819</td>\n",
       "      <td>0.122593</td>\n",
       "      <td>0.470444</td>\n",
       "      <td>0.014980</td>\n",
       "      <td>0.031150</td>\n",
       "      <td>0.100459</td>\n",
       "      <td>0.025799</td>\n",
       "      <td>0.037397</td>\n",
       "      <td>0.046854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>0.049915</td>\n",
       "      <td>0.158731</td>\n",
       "      <td>0.018066</td>\n",
       "      <td>0.101154</td>\n",
       "      <td>0.080634</td>\n",
       "      <td>0.182865</td>\n",
       "      <td>0.025762</td>\n",
       "      <td>0.053703</td>\n",
       "      <td>0.012526</td>\n",
       "      <td>0.023409</td>\n",
       "      <td>0.094649</td>\n",
       "      <td>0.422823</td>\n",
       "      <td>0.014237</td>\n",
       "      <td>0.029092</td>\n",
       "      <td>0.217897</td>\n",
       "      <td>0.022761</td>\n",
       "      <td>0.047412</td>\n",
       "      <td>0.043098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>0.088124</td>\n",
       "      <td>0.090358</td>\n",
       "      <td>0.015416</td>\n",
       "      <td>0.409141</td>\n",
       "      <td>0.055998</td>\n",
       "      <td>0.298602</td>\n",
       "      <td>0.028870</td>\n",
       "      <td>0.056503</td>\n",
       "      <td>0.012904</td>\n",
       "      <td>0.023948</td>\n",
       "      <td>0.098220</td>\n",
       "      <td>0.435365</td>\n",
       "      <td>0.011576</td>\n",
       "      <td>0.030768</td>\n",
       "      <td>0.236165</td>\n",
       "      <td>0.023384</td>\n",
       "      <td>0.035385</td>\n",
       "      <td>0.039606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>0.057898</td>\n",
       "      <td>0.109188</td>\n",
       "      <td>0.018393</td>\n",
       "      <td>0.060384</td>\n",
       "      <td>0.059077</td>\n",
       "      <td>0.306669</td>\n",
       "      <td>0.034469</td>\n",
       "      <td>0.064745</td>\n",
       "      <td>0.010530</td>\n",
       "      <td>0.023494</td>\n",
       "      <td>0.123750</td>\n",
       "      <td>0.511566</td>\n",
       "      <td>0.015812</td>\n",
       "      <td>0.029769</td>\n",
       "      <td>0.107490</td>\n",
       "      <td>0.027763</td>\n",
       "      <td>0.034852</td>\n",
       "      <td>0.064210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>0.052802</td>\n",
       "      <td>0.144088</td>\n",
       "      <td>0.018161</td>\n",
       "      <td>0.042982</td>\n",
       "      <td>0.056979</td>\n",
       "      <td>0.245807</td>\n",
       "      <td>0.027517</td>\n",
       "      <td>0.057819</td>\n",
       "      <td>0.011471</td>\n",
       "      <td>0.023897</td>\n",
       "      <td>0.100445</td>\n",
       "      <td>0.370947</td>\n",
       "      <td>0.013858</td>\n",
       "      <td>0.031281</td>\n",
       "      <td>0.112095</td>\n",
       "      <td>0.024491</td>\n",
       "      <td>0.033900</td>\n",
       "      <td>0.048185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>0.046012</td>\n",
       "      <td>0.141214</td>\n",
       "      <td>0.014533</td>\n",
       "      <td>0.548601</td>\n",
       "      <td>0.048294</td>\n",
       "      <td>0.249509</td>\n",
       "      <td>0.029163</td>\n",
       "      <td>0.051298</td>\n",
       "      <td>0.011464</td>\n",
       "      <td>0.024158</td>\n",
       "      <td>0.100103</td>\n",
       "      <td>0.342991</td>\n",
       "      <td>0.010061</td>\n",
       "      <td>0.030579</td>\n",
       "      <td>0.070950</td>\n",
       "      <td>0.024954</td>\n",
       "      <td>0.035400</td>\n",
       "      <td>0.049399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>777 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Crime  Thriller   Fantasy    Horror    Sci-Fi    Comedy  Documentary  \\\n",
       "0    0.052388  0.085766  0.017553  0.047432  0.029959  0.358913     0.025432   \n",
       "1    0.049774  0.110978  0.018673  0.042009  0.052269  0.298965     0.026855   \n",
       "2    0.048515  0.082972  0.017452  0.924401  0.051143  0.273917     0.028854   \n",
       "3    0.070496  0.157967  0.018502  0.052650  0.068607  0.375741     0.034541   \n",
       "4    0.054056  0.103110  0.018724  0.056426  0.054847  0.262357     0.030098   \n",
       "..        ...       ...       ...       ...       ...       ...          ...   \n",
       "772  0.049915  0.158731  0.018066  0.101154  0.080634  0.182865     0.025762   \n",
       "773  0.088124  0.090358  0.015416  0.409141  0.055998  0.298602     0.028870   \n",
       "774  0.057898  0.109188  0.018393  0.060384  0.059077  0.306669     0.034469   \n",
       "775  0.052802  0.144088  0.018161  0.042982  0.056979  0.245807     0.027517   \n",
       "776  0.046012  0.141214  0.014533  0.548601  0.048294  0.249509     0.029163   \n",
       "\n",
       "     Adventure  Film-Noir  Animation   Romance     Drama   Western   Musical  \\\n",
       "0     0.132096   0.011952   0.009268  0.113822  0.368692  0.015071  0.061539   \n",
       "1     0.064355   0.011464   0.024774  0.107312  0.358935  0.014587  0.031876   \n",
       "2     0.051483   0.019078   0.019941  0.107947  0.352339  0.008229  0.030006   \n",
       "3     0.082037   0.012114   0.023979  0.158922  0.396230  0.014563  0.028537   \n",
       "4     0.058324   0.012319   0.024819  0.122593  0.470444  0.014980  0.031150   \n",
       "..         ...        ...        ...       ...       ...       ...       ...   \n",
       "772   0.053703   0.012526   0.023409  0.094649  0.422823  0.014237  0.029092   \n",
       "773   0.056503   0.012904   0.023948  0.098220  0.435365  0.011576  0.030768   \n",
       "774   0.064745   0.010530   0.023494  0.123750  0.511566  0.015812  0.029769   \n",
       "775   0.057819   0.011471   0.023897  0.100445  0.370947  0.013858  0.031281   \n",
       "776   0.051298   0.011464   0.024158  0.100103  0.342991  0.010061  0.030579   \n",
       "\n",
       "       Action   Mystery       War  Children's  \n",
       "0    0.081528  0.025350  0.058420    0.285543  \n",
       "1    0.103609  0.025515  0.031971    0.045153  \n",
       "2    0.091558  0.020953  0.035023    0.043738  \n",
       "3    0.122983  0.054794  0.034700    0.050521  \n",
       "4    0.100459  0.025799  0.037397    0.046854  \n",
       "..        ...       ...       ...         ...  \n",
       "772  0.217897  0.022761  0.047412    0.043098  \n",
       "773  0.236165  0.023384  0.035385    0.039606  \n",
       "774  0.107490  0.027763  0.034852    0.064210  \n",
       "775  0.112095  0.024491  0.033900    0.048185  \n",
       "776  0.070950  0.024954  0.035400    0.049399  \n",
       "\n",
       "[777 rows x 18 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred_svm=y_test_pred.copy()\n",
    "y_test_pred_svm=np.array(y_test_pred_svm)\n",
    "submission_svm = pd.read_csv('submission.csv')\n",
    "i=0\n",
    "for label in genre2idx.keys():\n",
    "    submission_svm[label]=y_test_pred_svm[i][:,1]\n",
    "    i+=1\n",
    "submission_svm[genre2idx.keys()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5581570856570857"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_prediction__trainids = np.argsort(-submission_svm[genre2idx.keys()],axis=1)\n",
    "top_10_prediction_trainids = sorted_prediction__trainids[:,:5]\n",
    "def get_column_names_train(row):\n",
    "    return list(vectors_labels.columns[row == 1])\n",
    "vectors_labels_new=vectors_labels.apply(get_column_names_train,axis=1).tolist()\n",
    "mapk(vectors_labels_new,top_10_prediction_trainids,k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.45370978332239004, 0.18100000000000013)"
      ]
     },
     "execution_count": 606,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions=np.array(submission_svm[genre2idx.keys()]).copy()\n",
    "threshold=0.01\n",
    "maxvalue=0\n",
    "bestT=0\n",
    "for t in range(990):\n",
    "    predictions_new=(predictions>=threshold).astype(int)\n",
    "    tempval=f1_score(y_test,predictions_new,average=\"micro\")\n",
    "    if maxvalue< tempval:\n",
    "        maxvalue=tempval\n",
    "        bestT=threshold\n",
    "    threshold+=0.001\n",
    "maxvalue,bestT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix, hstack\n",
    "def add_feature(X, feature_to_add):\n",
    "    return hstack([X, csr_matrix(feature_to_add).T], 'csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_classifier = LogisticRegression(C=1.44)\n",
    "submission_chains = pd.DataFrame(columns=genre2idx.keys())\n",
    "data_classifier=data.copy()\n",
    "x_train_classfier=x_train.copy()\n",
    "y_train_classfier=y_train.copy()\n",
    "x_test_classfier=x_test.copy()\n",
    "y_test_classfier=y_test.copy()\n",
    "\n",
    "for label in genre2idx.keys():\n",
    "    print('... Processing {}'.format(label))\n",
    "    y = data_classifier[label]\n",
    "    # train the model using X_dtm & y\n",
    "    logreg_classifier.fit(x_train_classfier, y)\n",
    "    # compute the training accuracy\n",
    "    y_pred_X = logreg_classifier.predict(x_train_classfier)\n",
    "    print('Training accuracy is {}'.format(f1_score(y, y_pred_X)))\n",
    "    # make predictions from test_X\n",
    "    test_y = logreg_classifier.predict(x_test_classfier)\n",
    "    # compute the predicted probabilities for X_test_dtm\n",
    "    test_y_prob = logreg_classifier.predict_proba(x_test_classfier)[:,1]\n",
    "    submission_chains[label] = test_y_prob\n",
    "    x_train_classfier=add_feature(x_train_classfier,y)\n",
    "    print('Shape of X_dtm is now {}'.format(x_train_classfier.shape))\n",
    "    # chain current label predictions to test_X_dtm\n",
    "    x_test_classfier = add_feature(x_test_classfier, test_y)\n",
    "    print('Shape of test_X_dtm is now {}'.format(x_test_classfier.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4440129449838188, 0.16300000000000012)"
      ]
     },
     "execution_count": 600,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions1=np.array(submission_chains[genre2idx.keys()])\n",
    "threshold=0.01\n",
    "maxvalue=0\n",
    "bestT=0\n",
    "for t in range(990):\n",
    "    predictions_new=(predictions1>=threshold).astype(int)\n",
    "    tempval=f1_score(y_test,predictions_new,average=\"micro\")\n",
    "    if maxvalue< tempval:\n",
    "        maxvalue=tempval\n",
    "        bestT=threshold\n",
    "    threshold+=0.001\n",
    "maxvalue,bestT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5477995852995853"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_prediction__trainids = np.argsort(-submission_chains[genre2idx.keys()],axis=1)\n",
    "top_10_prediction_trainids = sorted_prediction__trainids[:,:5]\n",
    "def get_column_names_train(row):\n",
    "    return list(vectors_labels.columns[row == 1])\n",
    "vectors_labels_new=vectors_labels.apply(get_column_names_train,axis=1).tolist()\n",
    "mapk(vectors_labels_new,top_10_prediction_trainids,k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_combined=(submission_binary_combined[genre2idx.keys()]+submission_binary[genre2idx.keys()]+submission_boost[genre2idx.keys()]+submission_neural[genre2idx.keys()]\n",
    "                     +submission_chains[genre2idx.keys()]+res[genre2idx.keys()])/6\n",
    "# submission_combined=(submission_binary_combined[genre2idx.keys()]+submission_boost[genre2idx.keys()]+submission_neural+submission_svm[genre2idx.keys()])/5\n",
    "# → result:(0.4596358639642735, 0.4080000000000003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Crime</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Western</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Action</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>War</th>\n",
       "      <th>Children's</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.176391</td>\n",
       "      <td>0.219013</td>\n",
       "      <td>0.168697</td>\n",
       "      <td>0.206440</td>\n",
       "      <td>0.211677</td>\n",
       "      <td>0.768706</td>\n",
       "      <td>0.183929</td>\n",
       "      <td>0.407105</td>\n",
       "      <td>0.136571</td>\n",
       "      <td>0.202807</td>\n",
       "      <td>0.227849</td>\n",
       "      <td>0.430577</td>\n",
       "      <td>0.118985</td>\n",
       "      <td>0.442738</td>\n",
       "      <td>0.212680</td>\n",
       "      <td>0.191149</td>\n",
       "      <td>0.368403</td>\n",
       "      <td>0.610549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.278060</td>\n",
       "      <td>0.322192</td>\n",
       "      <td>0.162442</td>\n",
       "      <td>0.265155</td>\n",
       "      <td>0.258714</td>\n",
       "      <td>0.547702</td>\n",
       "      <td>0.161921</td>\n",
       "      <td>0.322953</td>\n",
       "      <td>0.163651</td>\n",
       "      <td>0.163514</td>\n",
       "      <td>0.321709</td>\n",
       "      <td>0.659931</td>\n",
       "      <td>0.157544</td>\n",
       "      <td>0.292766</td>\n",
       "      <td>0.319099</td>\n",
       "      <td>0.204790</td>\n",
       "      <td>0.199972</td>\n",
       "      <td>0.215505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.093120</td>\n",
       "      <td>0.311348</td>\n",
       "      <td>0.100230</td>\n",
       "      <td>0.931806</td>\n",
       "      <td>0.330463</td>\n",
       "      <td>0.327700</td>\n",
       "      <td>0.110915</td>\n",
       "      <td>0.223795</td>\n",
       "      <td>0.133798</td>\n",
       "      <td>0.087824</td>\n",
       "      <td>0.158985</td>\n",
       "      <td>0.335821</td>\n",
       "      <td>0.146755</td>\n",
       "      <td>0.104655</td>\n",
       "      <td>0.295868</td>\n",
       "      <td>0.219596</td>\n",
       "      <td>0.130015</td>\n",
       "      <td>0.069956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.278306</td>\n",
       "      <td>0.347612</td>\n",
       "      <td>0.144646</td>\n",
       "      <td>0.252681</td>\n",
       "      <td>0.256591</td>\n",
       "      <td>0.477976</td>\n",
       "      <td>0.139756</td>\n",
       "      <td>0.195668</td>\n",
       "      <td>0.162581</td>\n",
       "      <td>0.120224</td>\n",
       "      <td>0.385473</td>\n",
       "      <td>0.630808</td>\n",
       "      <td>0.136967</td>\n",
       "      <td>0.114726</td>\n",
       "      <td>0.292067</td>\n",
       "      <td>0.290701</td>\n",
       "      <td>0.158189</td>\n",
       "      <td>0.166323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.275387</td>\n",
       "      <td>0.494055</td>\n",
       "      <td>0.214887</td>\n",
       "      <td>0.348526</td>\n",
       "      <td>0.319675</td>\n",
       "      <td>0.446924</td>\n",
       "      <td>0.205570</td>\n",
       "      <td>0.319370</td>\n",
       "      <td>0.179230</td>\n",
       "      <td>0.250376</td>\n",
       "      <td>0.349409</td>\n",
       "      <td>0.693868</td>\n",
       "      <td>0.138196</td>\n",
       "      <td>0.253806</td>\n",
       "      <td>0.343578</td>\n",
       "      <td>0.272239</td>\n",
       "      <td>0.258276</td>\n",
       "      <td>0.308745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>0.258209</td>\n",
       "      <td>0.559333</td>\n",
       "      <td>0.198645</td>\n",
       "      <td>0.368838</td>\n",
       "      <td>0.350797</td>\n",
       "      <td>0.336441</td>\n",
       "      <td>0.186011</td>\n",
       "      <td>0.308926</td>\n",
       "      <td>0.170965</td>\n",
       "      <td>0.238495</td>\n",
       "      <td>0.287940</td>\n",
       "      <td>0.716115</td>\n",
       "      <td>0.130200</td>\n",
       "      <td>0.246497</td>\n",
       "      <td>0.624298</td>\n",
       "      <td>0.260302</td>\n",
       "      <td>0.295158</td>\n",
       "      <td>0.292855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>0.140243</td>\n",
       "      <td>0.148009</td>\n",
       "      <td>0.158395</td>\n",
       "      <td>0.304174</td>\n",
       "      <td>0.207704</td>\n",
       "      <td>0.348891</td>\n",
       "      <td>0.119633</td>\n",
       "      <td>0.248926</td>\n",
       "      <td>0.099779</td>\n",
       "      <td>0.128757</td>\n",
       "      <td>0.083494</td>\n",
       "      <td>0.373150</td>\n",
       "      <td>0.112462</td>\n",
       "      <td>0.118852</td>\n",
       "      <td>0.664249</td>\n",
       "      <td>0.125234</td>\n",
       "      <td>0.162681</td>\n",
       "      <td>0.226466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>0.110211</td>\n",
       "      <td>0.196329</td>\n",
       "      <td>0.065961</td>\n",
       "      <td>0.132358</td>\n",
       "      <td>0.078193</td>\n",
       "      <td>0.419790</td>\n",
       "      <td>0.211767</td>\n",
       "      <td>0.115046</td>\n",
       "      <td>0.068812</td>\n",
       "      <td>0.101147</td>\n",
       "      <td>0.179732</td>\n",
       "      <td>0.583268</td>\n",
       "      <td>0.082952</td>\n",
       "      <td>0.070085</td>\n",
       "      <td>0.149504</td>\n",
       "      <td>0.062566</td>\n",
       "      <td>0.084439</td>\n",
       "      <td>0.150476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>0.287932</td>\n",
       "      <td>0.348579</td>\n",
       "      <td>0.158524</td>\n",
       "      <td>0.417964</td>\n",
       "      <td>0.261506</td>\n",
       "      <td>0.496419</td>\n",
       "      <td>0.161758</td>\n",
       "      <td>0.237357</td>\n",
       "      <td>0.165492</td>\n",
       "      <td>0.158379</td>\n",
       "      <td>0.331855</td>\n",
       "      <td>0.573173</td>\n",
       "      <td>0.157194</td>\n",
       "      <td>0.193174</td>\n",
       "      <td>0.328894</td>\n",
       "      <td>0.208239</td>\n",
       "      <td>0.203074</td>\n",
       "      <td>0.200781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>0.220292</td>\n",
       "      <td>0.364178</td>\n",
       "      <td>0.126370</td>\n",
       "      <td>0.504113</td>\n",
       "      <td>0.251805</td>\n",
       "      <td>0.564758</td>\n",
       "      <td>0.132716</td>\n",
       "      <td>0.208048</td>\n",
       "      <td>0.140450</td>\n",
       "      <td>0.132081</td>\n",
       "      <td>0.276758</td>\n",
       "      <td>0.478726</td>\n",
       "      <td>0.117383</td>\n",
       "      <td>0.151787</td>\n",
       "      <td>0.259884</td>\n",
       "      <td>0.166927</td>\n",
       "      <td>0.163005</td>\n",
       "      <td>0.165915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>777 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Crime  Thriller   Fantasy    Horror    Sci-Fi    Comedy  Documentary  \\\n",
       "0    0.176391  0.219013  0.168697  0.206440  0.211677  0.768706     0.183929   \n",
       "1    0.278060  0.322192  0.162442  0.265155  0.258714  0.547702     0.161921   \n",
       "2    0.093120  0.311348  0.100230  0.931806  0.330463  0.327700     0.110915   \n",
       "3    0.278306  0.347612  0.144646  0.252681  0.256591  0.477976     0.139756   \n",
       "4    0.275387  0.494055  0.214887  0.348526  0.319675  0.446924     0.205570   \n",
       "..        ...       ...       ...       ...       ...       ...          ...   \n",
       "772  0.258209  0.559333  0.198645  0.368838  0.350797  0.336441     0.186011   \n",
       "773  0.140243  0.148009  0.158395  0.304174  0.207704  0.348891     0.119633   \n",
       "774  0.110211  0.196329  0.065961  0.132358  0.078193  0.419790     0.211767   \n",
       "775  0.287932  0.348579  0.158524  0.417964  0.261506  0.496419     0.161758   \n",
       "776  0.220292  0.364178  0.126370  0.504113  0.251805  0.564758     0.132716   \n",
       "\n",
       "     Adventure  Film-Noir  Animation   Romance     Drama   Western   Musical  \\\n",
       "0     0.407105   0.136571   0.202807  0.227849  0.430577  0.118985  0.442738   \n",
       "1     0.322953   0.163651   0.163514  0.321709  0.659931  0.157544  0.292766   \n",
       "2     0.223795   0.133798   0.087824  0.158985  0.335821  0.146755  0.104655   \n",
       "3     0.195668   0.162581   0.120224  0.385473  0.630808  0.136967  0.114726   \n",
       "4     0.319370   0.179230   0.250376  0.349409  0.693868  0.138196  0.253806   \n",
       "..         ...        ...        ...       ...       ...       ...       ...   \n",
       "772   0.308926   0.170965   0.238495  0.287940  0.716115  0.130200  0.246497   \n",
       "773   0.248926   0.099779   0.128757  0.083494  0.373150  0.112462  0.118852   \n",
       "774   0.115046   0.068812   0.101147  0.179732  0.583268  0.082952  0.070085   \n",
       "775   0.237357   0.165492   0.158379  0.331855  0.573173  0.157194  0.193174   \n",
       "776   0.208048   0.140450   0.132081  0.276758  0.478726  0.117383  0.151787   \n",
       "\n",
       "       Action   Mystery       War  Children's  \n",
       "0    0.212680  0.191149  0.368403    0.610549  \n",
       "1    0.319099  0.204790  0.199972    0.215505  \n",
       "2    0.295868  0.219596  0.130015    0.069956  \n",
       "3    0.292067  0.290701  0.158189    0.166323  \n",
       "4    0.343578  0.272239  0.258276    0.308745  \n",
       "..        ...       ...       ...         ...  \n",
       "772  0.624298  0.260302  0.295158    0.292855  \n",
       "773  0.664249  0.125234  0.162681    0.226466  \n",
       "774  0.149504  0.062566  0.084439    0.150476  \n",
       "775  0.328894  0.208239  0.203074    0.200781  \n",
       "776  0.259884  0.166927  0.163005    0.165915  \n",
       "\n",
       "[777 rows x 18 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.568523881023881"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_prediction__trainids = np.argsort(-submission_combined[genre2idx.keys()],axis=1)\n",
    "top_10_prediction_trainids = sorted_prediction__trainids[:,:5]\n",
    "def get_column_names_train(row):\n",
    "    return list(vectors_labels.columns[row == 1])\n",
    "vectors_labels_new=vectors_labels.apply(get_column_names_train,axis=1).tolist()\n",
    "mapk(vectors_labels_new,top_10_prediction_trainids,k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_combined.to_csv('submission1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc=pd.DataFrame()\n",
    "abc=submission_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1650"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_train[\"movieid\"].iloc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission1=pd.read_csv('submission1.csv')\n",
    "submission2=pd.read_csv('submission2.csv')\n",
    "submission3=pd.read_csv('submission3.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_2836\\572759920.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  missing_movie_ids1[label]=0\n"
     ]
    }
   ],
   "source": [
    "missing_movie_ids1 = submission2[~submission2['movieid'].isin(submission1['movieid'])]\n",
    "for label in genre2idx.keys():\n",
    "    missing_movie_ids1[label]=0\n",
    "genre_movieid=list(genre2idx.keys())\n",
    "genre_movieid.append('movieid')\n",
    "submission1 = pd.concat([submission1[genre_movieid], missing_movie_ids1[genre_movieid]], ignore_index=True).sort_values(by='movieid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_2836\\2670123946.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  missing_movie_ids3[label]=0\n"
     ]
    }
   ],
   "source": [
    "missing_movie_ids3 = submission2[~submission2['movieid'].isin(submission3['movieid'])]\n",
    "for label in genre2idx.keys():\n",
    "    missing_movie_ids3[label]=0\n",
    "genre_movieid=list(genre2idx.keys())\n",
    "genre_movieid.append('movieid')\n",
    "submission3 = pd.concat([submission3[genre_movieid], missing_movie_ids3[genre_movieid]], ignore_index=True).sort_values(by='movieid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission2=submission2.sort_values(by='movieid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sorted=data.sort_values(by='movieid').set_index('movieid')\n",
    "vectors_labels=pd.DataFrame(np.array(data_sorted[genre2idx.keys()]))\n",
    "w1=0\n",
    "w2=1\n",
    "w3=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission2=submission2.set_index('movieid')\n",
    "submission1=submission1.set_index('movieid')\n",
    "submission3=submission3.set_index('movieid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission3=submission3.set_index('movieid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Crime</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Western</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Action</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>War</th>\n",
       "      <th>Children's</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movieid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.870663e-07</td>\n",
       "      <td>5.588573e-03</td>\n",
       "      <td>4.905767e-01</td>\n",
       "      <td>9.714553e-01</td>\n",
       "      <td>0.759675</td>\n",
       "      <td>4.993133e-07</td>\n",
       "      <td>5.294202e-08</td>\n",
       "      <td>0.001620</td>\n",
       "      <td>6.519864e-03</td>\n",
       "      <td>2.471888e-10</td>\n",
       "      <td>1.180897e-09</td>\n",
       "      <td>0.157409</td>\n",
       "      <td>8.858831e-09</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>7.059093e-06</td>\n",
       "      <td>2.320997e-08</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.646935e-02</td>\n",
       "      <td>7.114165e-01</td>\n",
       "      <td>7.515992e-02</td>\n",
       "      <td>7.919439e-01</td>\n",
       "      <td>0.395226</td>\n",
       "      <td>2.943085e-04</td>\n",
       "      <td>2.400148e-05</td>\n",
       "      <td>0.028851</td>\n",
       "      <td>2.953669e-01</td>\n",
       "      <td>2.462466e-06</td>\n",
       "      <td>3.286522e-05</td>\n",
       "      <td>0.057991</td>\n",
       "      <td>3.826486e-05</td>\n",
       "      <td>0.001347</td>\n",
       "      <td>5.744367e-02</td>\n",
       "      <td>2.386100e-04</td>\n",
       "      <td>0.010462</td>\n",
       "      <td>0.001200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.703023e-09</td>\n",
       "      <td>6.300670e-08</td>\n",
       "      <td>2.244248e-07</td>\n",
       "      <td>1.101623e-04</td>\n",
       "      <td>0.998038</td>\n",
       "      <td>2.711532e-09</td>\n",
       "      <td>7.601015e-08</td>\n",
       "      <td>0.025326</td>\n",
       "      <td>2.474137e-06</td>\n",
       "      <td>4.268960e-15</td>\n",
       "      <td>2.123879e-12</td>\n",
       "      <td>0.007880</td>\n",
       "      <td>1.670983e-12</td>\n",
       "      <td>0.925919</td>\n",
       "      <td>9.657675e-09</td>\n",
       "      <td>4.077637e-15</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.709979e-06</td>\n",
       "      <td>2.027540e-06</td>\n",
       "      <td>9.660791e-08</td>\n",
       "      <td>3.736447e-06</td>\n",
       "      <td>0.724210</td>\n",
       "      <td>1.777470e-04</td>\n",
       "      <td>4.004234e-05</td>\n",
       "      <td>0.900848</td>\n",
       "      <td>1.284414e-06</td>\n",
       "      <td>2.511105e-07</td>\n",
       "      <td>2.761061e-08</td>\n",
       "      <td>0.001773</td>\n",
       "      <td>1.778810e-05</td>\n",
       "      <td>0.198830</td>\n",
       "      <td>1.078945e-06</td>\n",
       "      <td>1.205497e-06</td>\n",
       "      <td>0.007763</td>\n",
       "      <td>0.000331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.953288e-06</td>\n",
       "      <td>7.385816e-06</td>\n",
       "      <td>4.384601e-07</td>\n",
       "      <td>6.189873e-05</td>\n",
       "      <td>0.983944</td>\n",
       "      <td>8.971808e-07</td>\n",
       "      <td>3.012010e-07</td>\n",
       "      <td>0.003301</td>\n",
       "      <td>3.472895e-06</td>\n",
       "      <td>9.501677e-12</td>\n",
       "      <td>1.861406e-08</td>\n",
       "      <td>0.001732</td>\n",
       "      <td>6.593625e-10</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>6.486861e-06</td>\n",
       "      <td>4.955769e-10</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3945</th>\n",
       "      <td>1.828408e-03</td>\n",
       "      <td>5.222157e-01</td>\n",
       "      <td>4.428852e-01</td>\n",
       "      <td>9.723589e-01</td>\n",
       "      <td>0.431562</td>\n",
       "      <td>3.014984e-05</td>\n",
       "      <td>2.223346e-07</td>\n",
       "      <td>0.002530</td>\n",
       "      <td>2.268593e-01</td>\n",
       "      <td>7.400577e-08</td>\n",
       "      <td>2.561600e-07</td>\n",
       "      <td>0.112610</td>\n",
       "      <td>1.732802e-06</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>3.686572e-03</td>\n",
       "      <td>3.434829e-05</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3947</th>\n",
       "      <td>5.709537e-04</td>\n",
       "      <td>1.113671e-04</td>\n",
       "      <td>3.283138e-07</td>\n",
       "      <td>2.886468e-06</td>\n",
       "      <td>0.069801</td>\n",
       "      <td>3.842392e-04</td>\n",
       "      <td>6.744616e-07</td>\n",
       "      <td>0.001841</td>\n",
       "      <td>1.744801e-06</td>\n",
       "      <td>3.459906e-07</td>\n",
       "      <td>5.272710e-06</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>4.058358e-06</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>2.639322e-04</td>\n",
       "      <td>1.360133e-04</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3948</th>\n",
       "      <td>9.325756e-08</td>\n",
       "      <td>1.222899e-07</td>\n",
       "      <td>5.033113e-09</td>\n",
       "      <td>5.860165e-06</td>\n",
       "      <td>0.998683</td>\n",
       "      <td>1.283153e-09</td>\n",
       "      <td>5.818299e-10</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>5.115896e-08</td>\n",
       "      <td>5.768047e-17</td>\n",
       "      <td>9.404320e-11</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>1.775717e-14</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.760225e-07</td>\n",
       "      <td>2.757559e-14</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3949</th>\n",
       "      <td>1.977016e-06</td>\n",
       "      <td>1.358552e-07</td>\n",
       "      <td>1.562951e-10</td>\n",
       "      <td>2.349096e-08</td>\n",
       "      <td>0.223578</td>\n",
       "      <td>1.670921e-04</td>\n",
       "      <td>5.517305e-06</td>\n",
       "      <td>0.990480</td>\n",
       "      <td>9.491729e-09</td>\n",
       "      <td>1.016626e-07</td>\n",
       "      <td>2.456722e-09</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>3.429307e-05</td>\n",
       "      <td>0.016114</td>\n",
       "      <td>9.864890e-08</td>\n",
       "      <td>5.276322e-06</td>\n",
       "      <td>0.006156</td>\n",
       "      <td>0.000029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3950</th>\n",
       "      <td>3.799998e-05</td>\n",
       "      <td>1.369495e-06</td>\n",
       "      <td>5.406476e-11</td>\n",
       "      <td>1.026095e-08</td>\n",
       "      <td>0.017750</td>\n",
       "      <td>1.084603e-03</td>\n",
       "      <td>4.111282e-06</td>\n",
       "      <td>0.993474</td>\n",
       "      <td>1.008058e-08</td>\n",
       "      <td>1.564598e-06</td>\n",
       "      <td>1.837668e-08</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>5.139986e-04</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>8.700396e-07</td>\n",
       "      <td>4.247465e-04</td>\n",
       "      <td>0.011929</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3106 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Crime      Thriller       Fantasy        Horror    Sci-Fi  \\\n",
       "movieid                                                                     \n",
       "1        3.870663e-07  5.588573e-03  4.905767e-01  9.714553e-01  0.759675   \n",
       "2        7.646935e-02  7.114165e-01  7.515992e-02  7.919439e-01  0.395226   \n",
       "3        2.703023e-09  6.300670e-08  2.244248e-07  1.101623e-04  0.998038   \n",
       "4        6.709979e-06  2.027540e-06  9.660791e-08  3.736447e-06  0.724210   \n",
       "5        8.953288e-06  7.385816e-06  4.384601e-07  6.189873e-05  0.983944   \n",
       "...               ...           ...           ...           ...       ...   \n",
       "3945     1.828408e-03  5.222157e-01  4.428852e-01  9.723589e-01  0.431562   \n",
       "3947     5.709537e-04  1.113671e-04  3.283138e-07  2.886468e-06  0.069801   \n",
       "3948     9.325756e-08  1.222899e-07  5.033113e-09  5.860165e-06  0.998683   \n",
       "3949     1.977016e-06  1.358552e-07  1.562951e-10  2.349096e-08  0.223578   \n",
       "3950     3.799998e-05  1.369495e-06  5.406476e-11  1.026095e-08  0.017750   \n",
       "\n",
       "               Comedy   Documentary  Adventure     Film-Noir     Animation  \\\n",
       "movieid                                                                      \n",
       "1        4.993133e-07  5.294202e-08   0.001620  6.519864e-03  2.471888e-10   \n",
       "2        2.943085e-04  2.400148e-05   0.028851  2.953669e-01  2.462466e-06   \n",
       "3        2.711532e-09  7.601015e-08   0.025326  2.474137e-06  4.268960e-15   \n",
       "4        1.777470e-04  4.004234e-05   0.900848  1.284414e-06  2.511105e-07   \n",
       "5        8.971808e-07  3.012010e-07   0.003301  3.472895e-06  9.501677e-12   \n",
       "...               ...           ...        ...           ...           ...   \n",
       "3945     3.014984e-05  2.223346e-07   0.002530  2.268593e-01  7.400577e-08   \n",
       "3947     3.842392e-04  6.744616e-07   0.001841  1.744801e-06  3.459906e-07   \n",
       "3948     1.283153e-09  5.818299e-10   0.000045  5.115896e-08  5.768047e-17   \n",
       "3949     1.670921e-04  5.517305e-06   0.990480  9.491729e-09  1.016626e-07   \n",
       "3950     1.084603e-03  4.111282e-06   0.993474  1.008058e-08  1.564598e-06   \n",
       "\n",
       "              Romance     Drama       Western   Musical        Action  \\\n",
       "movieid                                                                 \n",
       "1        1.180897e-09  0.157409  8.858831e-09  0.000003  7.059093e-06   \n",
       "2        3.286522e-05  0.057991  3.826486e-05  0.001347  5.744367e-02   \n",
       "3        2.123879e-12  0.007880  1.670983e-12  0.925919  9.657675e-09   \n",
       "4        2.761061e-08  0.001773  1.778810e-05  0.198830  1.078945e-06   \n",
       "5        1.861406e-08  0.001732  6.593625e-10  0.000575  6.486861e-06   \n",
       "...               ...       ...           ...       ...           ...   \n",
       "3945     2.561600e-07  0.112610  1.732802e-06  0.000028  3.686572e-03   \n",
       "3947     5.272710e-06  0.000015  4.058358e-06  0.000007  2.639322e-04   \n",
       "3948     9.404320e-11  0.000235  1.775717e-14  0.000003  1.760225e-07   \n",
       "3949     2.456722e-09  0.000057  3.429307e-05  0.016114  9.864890e-08   \n",
       "3950     1.837668e-08  0.000006  5.139986e-04  0.002041  8.700396e-07   \n",
       "\n",
       "              Mystery       War  Children's  \n",
       "movieid                                      \n",
       "1        2.320997e-08  0.000005    0.000002  \n",
       "2        2.386100e-04  0.010462    0.001200  \n",
       "3        4.077637e-15  0.000075    0.000042  \n",
       "4        1.205497e-06  0.007763    0.000331  \n",
       "5        4.955769e-10  0.000130    0.000100  \n",
       "...               ...       ...         ...  \n",
       "3945     3.434829e-05  0.000162    0.000019  \n",
       "3947     1.360133e-04  0.000074    0.000008  \n",
       "3948     2.757559e-14  0.000002    0.000003  \n",
       "3949     5.276322e-06  0.006156    0.000029  \n",
       "3950     4.247465e-04  0.011929    0.000013  \n",
       "\n",
       "[3106 rows x 18 columns]"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.941039475567003"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_prediction__trainids = np.argsort(-w2*submission2[genre2idx.keys()],axis=1)\n",
    "top_10_prediction_trainids = sorted_prediction__trainids[:,:5]\n",
    "vectors_labels_new=vectors_labels.apply(get_column_names_train,axis=1).tolist()\n",
    "mapk(vectors_labels_new,top_10_prediction_trainids,k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.941039475567003"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sorted_prediction__trainids = np.argsort(-(w1*submission1[genre2idx.keys()]+w2*submission2[genre2idx.keys()]+w3*submission3[genre2idx.keys()]),axis=1)\n",
    "top_10_prediction_trainids = sorted_prediction__trainids[:,:5]\n",
    "vectors_labels_new=vectors_labels.apply(get_column_names_train,axis=1).tolist()\n",
    "mapk(vectors_labels_new,top_10_prediction_trainids,k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Crime</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Western</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Action</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>War</th>\n",
       "      <th>Children's</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movieid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.214781</td>\n",
       "      <td>0.215216</td>\n",
       "      <td>0.290702</td>\n",
       "      <td>0.184731</td>\n",
       "      <td>0.185374</td>\n",
       "      <td>0.833312</td>\n",
       "      <td>0.177995</td>\n",
       "      <td>0.240563</td>\n",
       "      <td>0.136458</td>\n",
       "      <td>0.611270</td>\n",
       "      <td>0.395927</td>\n",
       "      <td>0.499450</td>\n",
       "      <td>0.144926</td>\n",
       "      <td>0.194126</td>\n",
       "      <td>0.231850</td>\n",
       "      <td>0.160504</td>\n",
       "      <td>0.195047</td>\n",
       "      <td>0.696347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.336253</td>\n",
       "      <td>0.386172</td>\n",
       "      <td>0.576214</td>\n",
       "      <td>0.314173</td>\n",
       "      <td>0.345325</td>\n",
       "      <td>0.491683</td>\n",
       "      <td>0.202596</td>\n",
       "      <td>0.534830</td>\n",
       "      <td>0.194177</td>\n",
       "      <td>0.246026</td>\n",
       "      <td>0.383965</td>\n",
       "      <td>0.601640</td>\n",
       "      <td>0.195757</td>\n",
       "      <td>0.255639</td>\n",
       "      <td>0.420887</td>\n",
       "      <td>0.244757</td>\n",
       "      <td>0.247165</td>\n",
       "      <td>0.475969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.389836</td>\n",
       "      <td>0.252990</td>\n",
       "      <td>0.127938</td>\n",
       "      <td>0.188214</td>\n",
       "      <td>0.215542</td>\n",
       "      <td>0.886611</td>\n",
       "      <td>0.122305</td>\n",
       "      <td>0.393290</td>\n",
       "      <td>0.136478</td>\n",
       "      <td>0.114078</td>\n",
       "      <td>0.617529</td>\n",
       "      <td>0.540807</td>\n",
       "      <td>0.169220</td>\n",
       "      <td>0.136862</td>\n",
       "      <td>0.427944</td>\n",
       "      <td>0.178941</td>\n",
       "      <td>0.140781</td>\n",
       "      <td>0.200302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.266623</td>\n",
       "      <td>0.301254</td>\n",
       "      <td>0.167956</td>\n",
       "      <td>0.164441</td>\n",
       "      <td>0.216494</td>\n",
       "      <td>0.900115</td>\n",
       "      <td>0.149521</td>\n",
       "      <td>0.210166</td>\n",
       "      <td>0.130727</td>\n",
       "      <td>0.125084</td>\n",
       "      <td>0.390068</td>\n",
       "      <td>0.779512</td>\n",
       "      <td>0.133544</td>\n",
       "      <td>0.148458</td>\n",
       "      <td>0.327193</td>\n",
       "      <td>0.156889</td>\n",
       "      <td>0.208634</td>\n",
       "      <td>0.221387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.118297</td>\n",
       "      <td>0.167701</td>\n",
       "      <td>0.064509</td>\n",
       "      <td>0.587141</td>\n",
       "      <td>0.351221</td>\n",
       "      <td>0.813508</td>\n",
       "      <td>0.164921</td>\n",
       "      <td>0.139737</td>\n",
       "      <td>0.073927</td>\n",
       "      <td>0.147434</td>\n",
       "      <td>0.121471</td>\n",
       "      <td>0.090714</td>\n",
       "      <td>0.088341</td>\n",
       "      <td>0.149511</td>\n",
       "      <td>0.190585</td>\n",
       "      <td>0.090567</td>\n",
       "      <td>0.166557</td>\n",
       "      <td>0.107251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3945</th>\n",
       "      <td>0.186683</td>\n",
       "      <td>0.380050</td>\n",
       "      <td>0.202299</td>\n",
       "      <td>0.223847</td>\n",
       "      <td>0.408899</td>\n",
       "      <td>0.487908</td>\n",
       "      <td>0.234430</td>\n",
       "      <td>0.651804</td>\n",
       "      <td>0.145972</td>\n",
       "      <td>0.781890</td>\n",
       "      <td>0.184543</td>\n",
       "      <td>0.305934</td>\n",
       "      <td>0.129773</td>\n",
       "      <td>0.228166</td>\n",
       "      <td>0.396937</td>\n",
       "      <td>0.202232</td>\n",
       "      <td>0.345652</td>\n",
       "      <td>0.773757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3947</th>\n",
       "      <td>0.215519</td>\n",
       "      <td>0.661017</td>\n",
       "      <td>0.140618</td>\n",
       "      <td>0.207068</td>\n",
       "      <td>0.202069</td>\n",
       "      <td>0.445537</td>\n",
       "      <td>0.256794</td>\n",
       "      <td>0.211014</td>\n",
       "      <td>0.144831</td>\n",
       "      <td>0.130206</td>\n",
       "      <td>0.244069</td>\n",
       "      <td>0.618198</td>\n",
       "      <td>0.141478</td>\n",
       "      <td>0.147178</td>\n",
       "      <td>0.439926</td>\n",
       "      <td>0.172865</td>\n",
       "      <td>0.154578</td>\n",
       "      <td>0.160757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3948</th>\n",
       "      <td>0.300377</td>\n",
       "      <td>0.384110</td>\n",
       "      <td>0.250857</td>\n",
       "      <td>0.395989</td>\n",
       "      <td>0.371444</td>\n",
       "      <td>0.816830</td>\n",
       "      <td>0.232664</td>\n",
       "      <td>0.361447</td>\n",
       "      <td>0.204866</td>\n",
       "      <td>0.285412</td>\n",
       "      <td>0.374000</td>\n",
       "      <td>0.435701</td>\n",
       "      <td>0.151491</td>\n",
       "      <td>0.348460</td>\n",
       "      <td>0.371724</td>\n",
       "      <td>0.317198</td>\n",
       "      <td>0.289299</td>\n",
       "      <td>0.366677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3949</th>\n",
       "      <td>0.152371</td>\n",
       "      <td>0.352230</td>\n",
       "      <td>0.265730</td>\n",
       "      <td>0.129176</td>\n",
       "      <td>0.095795</td>\n",
       "      <td>0.406110</td>\n",
       "      <td>0.359175</td>\n",
       "      <td>0.133660</td>\n",
       "      <td>0.127517</td>\n",
       "      <td>0.112102</td>\n",
       "      <td>0.243990</td>\n",
       "      <td>0.839354</td>\n",
       "      <td>0.161184</td>\n",
       "      <td>0.083985</td>\n",
       "      <td>0.194956</td>\n",
       "      <td>0.098622</td>\n",
       "      <td>0.079632</td>\n",
       "      <td>0.131915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3950</th>\n",
       "      <td>0.333537</td>\n",
       "      <td>0.383208</td>\n",
       "      <td>0.189017</td>\n",
       "      <td>0.312585</td>\n",
       "      <td>0.306087</td>\n",
       "      <td>0.477236</td>\n",
       "      <td>0.192936</td>\n",
       "      <td>0.274626</td>\n",
       "      <td>0.191682</td>\n",
       "      <td>0.184385</td>\n",
       "      <td>0.378515</td>\n",
       "      <td>0.859160</td>\n",
       "      <td>0.188083</td>\n",
       "      <td>0.223782</td>\n",
       "      <td>0.375149</td>\n",
       "      <td>0.241332</td>\n",
       "      <td>0.233233</td>\n",
       "      <td>0.243390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3106 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Crime  Thriller   Fantasy    Horror    Sci-Fi    Comedy  \\\n",
       "movieid                                                               \n",
       "1        0.214781  0.215216  0.290702  0.184731  0.185374  0.833312   \n",
       "2        0.336253  0.386172  0.576214  0.314173  0.345325  0.491683   \n",
       "3        0.389836  0.252990  0.127938  0.188214  0.215542  0.886611   \n",
       "4        0.266623  0.301254  0.167956  0.164441  0.216494  0.900115   \n",
       "5        0.118297  0.167701  0.064509  0.587141  0.351221  0.813508   \n",
       "...           ...       ...       ...       ...       ...       ...   \n",
       "3945     0.186683  0.380050  0.202299  0.223847  0.408899  0.487908   \n",
       "3947     0.215519  0.661017  0.140618  0.207068  0.202069  0.445537   \n",
       "3948     0.300377  0.384110  0.250857  0.395989  0.371444  0.816830   \n",
       "3949     0.152371  0.352230  0.265730  0.129176  0.095795  0.406110   \n",
       "3950     0.333537  0.383208  0.189017  0.312585  0.306087  0.477236   \n",
       "\n",
       "         Documentary  Adventure  Film-Noir  Animation   Romance     Drama  \\\n",
       "movieid                                                                     \n",
       "1           0.177995   0.240563   0.136458   0.611270  0.395927  0.499450   \n",
       "2           0.202596   0.534830   0.194177   0.246026  0.383965  0.601640   \n",
       "3           0.122305   0.393290   0.136478   0.114078  0.617529  0.540807   \n",
       "4           0.149521   0.210166   0.130727   0.125084  0.390068  0.779512   \n",
       "5           0.164921   0.139737   0.073927   0.147434  0.121471  0.090714   \n",
       "...              ...        ...        ...        ...       ...       ...   \n",
       "3945        0.234430   0.651804   0.145972   0.781890  0.184543  0.305934   \n",
       "3947        0.256794   0.211014   0.144831   0.130206  0.244069  0.618198   \n",
       "3948        0.232664   0.361447   0.204866   0.285412  0.374000  0.435701   \n",
       "3949        0.359175   0.133660   0.127517   0.112102  0.243990  0.839354   \n",
       "3950        0.192936   0.274626   0.191682   0.184385  0.378515  0.859160   \n",
       "\n",
       "          Western   Musical    Action   Mystery       War  Children's  \n",
       "movieid                                                                \n",
       "1        0.144926  0.194126  0.231850  0.160504  0.195047    0.696347  \n",
       "2        0.195757  0.255639  0.420887  0.244757  0.247165    0.475969  \n",
       "3        0.169220  0.136862  0.427944  0.178941  0.140781    0.200302  \n",
       "4        0.133544  0.148458  0.327193  0.156889  0.208634    0.221387  \n",
       "5        0.088341  0.149511  0.190585  0.090567  0.166557    0.107251  \n",
       "...           ...       ...       ...       ...       ...         ...  \n",
       "3945     0.129773  0.228166  0.396937  0.202232  0.345652    0.773757  \n",
       "3947     0.141478  0.147178  0.439926  0.172865  0.154578    0.160757  \n",
       "3948     0.151491  0.348460  0.371724  0.317198  0.289299    0.366677  \n",
       "3949     0.161184  0.083985  0.194956  0.098622  0.079632    0.131915  \n",
       "3950     0.188083  0.223782  0.375149  0.241332  0.233233    0.243390  \n",
       "\n",
       "[3106 rows x 18 columns]"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2*submission2[genre2idx.keys()]+w1*submission1[genre2idx.keys()]+w3*submission3[genre2idx.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Crime</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Western</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Action</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>War</th>\n",
       "      <th>Children's</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2240</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2272</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2402</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1352</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3106 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Crime  Thriller  Fantasy  Horror  Sci-Fi  Comedy  Documentary  \\\n",
       "919     0.0       0.0      0.0     0.0     0.0     0.0          0.0   \n",
       "311     0.0       0.0      0.0     0.0     0.0     0.0          0.0   \n",
       "1511    0.0       0.0      0.0     0.0     0.0     0.0          0.0   \n",
       "376     0.0       0.0      0.0     0.0     0.0     0.0          0.0   \n",
       "925     0.0       0.0      0.0     0.0     0.0     0.0          0.0   \n",
       "...     ...       ...      ...     ...     ...     ...          ...   \n",
       "2240    0.0       0.0      0.0     0.0     0.0     0.0          0.0   \n",
       "2272    0.0       0.0      0.0     0.0     0.0     0.0          0.0   \n",
       "2402    0.0       0.0      0.0     0.0     0.0     0.0          0.0   \n",
       "1308    0.0       0.0      0.0     0.0     0.0     0.0          0.0   \n",
       "1352    0.0       0.0      0.0     0.0     0.0     0.0          0.0   \n",
       "\n",
       "      Adventure  Film-Noir  Animation  Romance  Drama  Western  Musical  \\\n",
       "919         0.0        0.0        0.0      0.0    0.0      0.0      0.0   \n",
       "311         0.0        0.0        0.0      0.0    0.0      0.0      0.0   \n",
       "1511        0.0        0.0        0.0      0.0    0.0      0.0      0.0   \n",
       "376         0.0        0.0        0.0      0.0    0.0      0.0      0.0   \n",
       "925         0.0        0.0        0.0      0.0    0.0      0.0      0.0   \n",
       "...         ...        ...        ...      ...    ...      ...      ...   \n",
       "2240        0.0        0.0        0.0      0.0    0.0      0.0      0.0   \n",
       "2272        0.0        0.0        0.0      0.0    0.0      0.0      0.0   \n",
       "2402        0.0        0.0        0.0      0.0    0.0      0.0      0.0   \n",
       "1308        0.0        0.0        0.0      0.0    0.0      0.0      0.0   \n",
       "1352        0.0        0.0        0.0      0.0    0.0      0.0      0.0   \n",
       "\n",
       "      Action  Mystery  War  Children's  \n",
       "919      0.0      0.0  0.0         0.0  \n",
       "311      0.0      0.0  0.0         0.0  \n",
       "1511     0.0      0.0  0.0         0.0  \n",
       "376      0.0      0.0  0.0         0.0  \n",
       "925      0.0      0.0  0.0         0.0  \n",
       "...      ...      ...  ...         ...  \n",
       "2240     0.0      0.0  0.0         0.0  \n",
       "2272     0.0      0.0  0.0         0.0  \n",
       "2402     0.0      0.0  0.0         0.0  \n",
       "1308     0.0      0.0  0.0         0.0  \n",
       "1352     0.0      0.0  0.0         0.0  \n",
       "\n",
       "[3106 rows x 18 columns]"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1*submission2[genre2idx.keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_movieids = list(set(submission1['movieid']).intersection(submission2['movieid']).intersection(submission3['movieid']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission1=submission1[submission1['movieid'].isin(common_movieids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission2=submission2[submission2['movieid'].isin(common_movieids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission3=submission3[submission3['movieid'].isin(common_movieids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieid</th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1650</td>\n",
       "      <td>Washington Square (1997)</td>\n",
       "      <td>[Drama]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>185</td>\n",
       "      <td>Net, The (1995)</td>\n",
       "      <td>[Sci-Fi, Thriller]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1377</td>\n",
       "      <td>Batman Returns (1992)</td>\n",
       "      <td>[Action, Adventure, Comedy, Crime]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3204</td>\n",
       "      <td>Boys from Brazil, The (1978)</td>\n",
       "      <td>[Thriller]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2382</td>\n",
       "      <td>Police Academy 5: Assignment: Miami Beach (1988)</td>\n",
       "      <td>[Comedy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3099</th>\n",
       "      <td>2921</td>\n",
       "      <td>High Plains Drifter (1972)</td>\n",
       "      <td>[Western]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3100</th>\n",
       "      <td>502</td>\n",
       "      <td>Next Karate Kid, The (1994)</td>\n",
       "      <td>[Action, Children's]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3101</th>\n",
       "      <td>2539</td>\n",
       "      <td>Analyze This (1999)</td>\n",
       "      <td>[Comedy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3102</th>\n",
       "      <td>3038</td>\n",
       "      <td>Face in the Crowd, A (1957)</td>\n",
       "      <td>[Drama]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3105</th>\n",
       "      <td>1750</td>\n",
       "      <td>Star Kid (1997)</td>\n",
       "      <td>[Adventure, Children's, Fantasy, Sci-Fi]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2583 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      movieid                                             title  \\\n",
       "0        1650                          Washington Square (1997)   \n",
       "1         185                                   Net, The (1995)   \n",
       "2        1377                             Batman Returns (1992)   \n",
       "3        3204                      Boys from Brazil, The (1978)   \n",
       "7        2382  Police Academy 5: Assignment: Miami Beach (1988)   \n",
       "...       ...                                               ...   \n",
       "3099     2921                        High Plains Drifter (1972)   \n",
       "3100      502                       Next Karate Kid, The (1994)   \n",
       "3101     2539                               Analyze This (1999)   \n",
       "3102     3038                       Face in the Crowd, A (1957)   \n",
       "3105     1750                                   Star Kid (1997)   \n",
       "\n",
       "                                         genre  \n",
       "0                                      [Drama]  \n",
       "1                           [Sci-Fi, Thriller]  \n",
       "2           [Action, Adventure, Comedy, Crime]  \n",
       "3                                   [Thriller]  \n",
       "7                                     [Comedy]  \n",
       "...                                        ...  \n",
       "3099                                 [Western]  \n",
       "3100                      [Action, Children's]  \n",
       "3101                                  [Comedy]  \n",
       "3102                                   [Drama]  \n",
       "3105  [Adventure, Children's, Fantasy, Sci-Fi]  \n",
       "\n",
       "[2583 rows x 3 columns]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_train[movies_train['movieid'].isin(common_movieids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_column_names_train(row):\n",
    "    return list(vectors_labels.columns[row == 1])\n",
    "def internal_method(w1,w2,w3):\n",
    "    if w1+w2+w3>1:\n",
    "        return -1\n",
    "    else:\n",
    "        sorted_prediction__trainids = np.argsort(-(w1*submission1[genre2idx.keys()]+w2*submission2[genre2idx.keys()]+w3*submission3[genre2idx.keys()]),axis=1)\n",
    "        top_10_prediction_trainids = sorted_prediction__trainids[:,:5]\n",
    "        vectors_labels_new=vectors_labels.apply(get_column_names_train,axis=1).tolist()\n",
    "        return mapk(vectors_labels_new,top_10_prediction_trainids,k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |    w1     |    w2     |    w3     |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m-1.0     \u001b[0m | \u001b[0m0.07631  \u001b[0m | \u001b[0m0.7799   \u001b[0m | \u001b[0m0.4384   \u001b[0m |\n",
      "| \u001b[0m2        \u001b[0m | \u001b[0m-1.0     \u001b[0m | \u001b[0m0.7235   \u001b[0m | \u001b[0m0.978    \u001b[0m | \u001b[0m0.5385   \u001b[0m |\n",
      "| \u001b[95m3        \u001b[0m | \u001b[95m0.3481   \u001b[0m | \u001b[95m0.5011   \u001b[0m | \u001b[95m0.07205  \u001b[0m | \u001b[95m0.2684   \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m-1.0     \u001b[0m | \u001b[0m0.4999   \u001b[0m | \u001b[0m0.6792   \u001b[0m | \u001b[0m0.8037   \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m0.3432   \u001b[0m | \u001b[0m0.3809   \u001b[0m | \u001b[0m0.06594  \u001b[0m | \u001b[0m0.2881   \u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m0.2441   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m0.06505  \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m-1.0     \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m0.2441   \u001b[0m | \u001b[0m0.4968   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m0.08325  \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.8522   \u001b[0m |\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m-1.0     \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.4752   \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m0.08325  \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.4433   \u001b[0m |\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m-1.0     \u001b[0m | \u001b[0m0.4454   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.5685   \u001b[0m |\n",
      "| \u001b[95m14       \u001b[0m | \u001b[95m0.8885   \u001b[0m | \u001b[95m0.319    \u001b[0m | \u001b[95m0.2756   \u001b[0m | \u001b[95m0.08089  \u001b[0m |\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m-1.0     \u001b[0m | \u001b[0m0.9143   \u001b[0m | \u001b[0m0.7709   \u001b[0m | \u001b[0m0.1163   \u001b[0m |\n",
      "| \u001b[95m16       \u001b[0m | \u001b[95m0.9429   \u001b[0m | \u001b[95m0.08166  \u001b[0m | \u001b[95m0.4038   \u001b[0m | \u001b[95m0.0      \u001b[0m |\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m0.9397   \u001b[0m | \u001b[0m0.291    \u001b[0m | \u001b[0m0.5486   \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
      "| \u001b[0m18       \u001b[0m | \u001b[0m0.941    \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.7054   \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
      "| \u001b[0m19       \u001b[0m | \u001b[0m-1.0     \u001b[0m | \u001b[0m0.1628   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
      "| \u001b[0m20       \u001b[0m | \u001b[0m0.3409   \u001b[0m | \u001b[0m0.3793   \u001b[0m | \u001b[0m0.06529  \u001b[0m | \u001b[0m0.3004   \u001b[0m |\n",
      "| \u001b[0m21       \u001b[0m | \u001b[0m0.854    \u001b[0m | \u001b[0m0.1794   \u001b[0m | \u001b[0m0.4211   \u001b[0m | \u001b[0m0.2177   \u001b[0m |\n",
      "| \u001b[0m22       \u001b[0m | \u001b[0m0.9398   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.5422   \u001b[0m | \u001b[0m0.09978  \u001b[0m |\n",
      "| \u001b[0m23       \u001b[0m | \u001b[0m-1.0     \u001b[0m | \u001b[0m0.5962   \u001b[0m | \u001b[0m0.5211   \u001b[0m | \u001b[0m0.05322  \u001b[0m |\n",
      "| \u001b[95m24       \u001b[0m | \u001b[95m0.9433   \u001b[0m | \u001b[95m0.1249   \u001b[0m | \u001b[95m0.5785   \u001b[0m | \u001b[95m0.0      \u001b[0m |\n",
      "| \u001b[0m25       \u001b[0m | \u001b[0m-1.0     \u001b[0m | \u001b[0m0.4067   \u001b[0m | \u001b[0m0.2024   \u001b[0m | \u001b[0m0.7126   \u001b[0m |\n",
      "| \u001b[0m26       \u001b[0m | \u001b[0m-1.0     \u001b[0m | \u001b[0m0.1493   \u001b[0m | \u001b[0m0.7225   \u001b[0m | \u001b[0m0.9461   \u001b[0m |\n",
      "| \u001b[0m27       \u001b[0m | \u001b[0m0.3489   \u001b[0m | \u001b[0m0.3766   \u001b[0m | \u001b[0m0.07022  \u001b[0m | \u001b[0m0.3074   \u001b[0m |\n",
      "| \u001b[95m28       \u001b[0m | \u001b[95m0.9444   \u001b[0m | \u001b[95m0.2256   \u001b[0m | \u001b[95m0.678    \u001b[0m | \u001b[95m0.06959  \u001b[0m |\n",
      "| \u001b[0m29       \u001b[0m | \u001b[0m-1.0     \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "| \u001b[0m30       \u001b[0m | \u001b[0m0.6611   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.2725   \u001b[0m | \u001b[0m0.1988   \u001b[0m |\n",
      "| \u001b[0m31       \u001b[0m | \u001b[0m-1.0     \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.351    \u001b[0m |\n",
      "| \u001b[0m32       \u001b[0m | \u001b[0m0.336    \u001b[0m | \u001b[0m0.382    \u001b[0m | \u001b[0m0.06086  \u001b[0m | \u001b[0m0.288    \u001b[0m |\n",
      "| \u001b[0m33       \u001b[0m | \u001b[0m0.9393   \u001b[0m | \u001b[0m0.2253   \u001b[0m | \u001b[0m0.4312   \u001b[0m | \u001b[0m0.07422  \u001b[0m |\n",
      "| \u001b[0m34       \u001b[0m | \u001b[0m0.9271   \u001b[0m | \u001b[0m0.1877   \u001b[0m | \u001b[0m0.2239   \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
      "| \u001b[0m35       \u001b[0m | \u001b[0m0.5349   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.3208   \u001b[0m | \u001b[0m0.5045   \u001b[0m |\n",
      "| \u001b[0m36       \u001b[0m | \u001b[0m-1.0     \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.284    \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "| \u001b[0m37       \u001b[0m | \u001b[0m-1.0     \u001b[0m | \u001b[0m0.5347   \u001b[0m | \u001b[0m0.7544   \u001b[0m | \u001b[0m0.2169   \u001b[0m |\n",
      "| \u001b[0m38       \u001b[0m | \u001b[0m0.543    \u001b[0m | \u001b[0m0.1685   \u001b[0m | \u001b[0m0.2411   \u001b[0m | \u001b[0m0.3643   \u001b[0m |\n",
      "| \u001b[0m39       \u001b[0m | \u001b[0m0.941    \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.2844   \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
      "| \u001b[0m40       \u001b[0m | \u001b[0m-1.0     \u001b[0m | \u001b[0m0.02535  \u001b[0m | \u001b[0m0.774    \u001b[0m | \u001b[0m0.6505   \u001b[0m |\n",
      "| \u001b[0m41       \u001b[0m | \u001b[0m0.6751   \u001b[0m | \u001b[0m0.00534  \u001b[0m | \u001b[0m0.2784   \u001b[0m | \u001b[0m0.1971   \u001b[0m |\n",
      "| \u001b[0m42       \u001b[0m | \u001b[0m0.3577   \u001b[0m | \u001b[0m0.3805   \u001b[0m | \u001b[0m0.07609  \u001b[0m | \u001b[0m0.3054   \u001b[0m |\n",
      "| \u001b[0m43       \u001b[0m | \u001b[0m-1.0     \u001b[0m | \u001b[0m0.1985   \u001b[0m | \u001b[0m0.4286   \u001b[0m | \u001b[0m0.9306   \u001b[0m |\n",
      "| \u001b[0m44       \u001b[0m | \u001b[0m0.941    \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.547    \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
      "| \u001b[0m45       \u001b[0m | \u001b[0m0.9282   \u001b[0m | \u001b[0m0.2774   \u001b[0m | \u001b[0m0.3378   \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
      "| \u001b[0m46       \u001b[0m | \u001b[0m0.8931   \u001b[0m | \u001b[0m0.3138   \u001b[0m | \u001b[0m0.2843   \u001b[0m | \u001b[0m0.08502  \u001b[0m |\n",
      "| \u001b[0m47       \u001b[0m | \u001b[0m0.9385   \u001b[0m | \u001b[0m0.209    \u001b[0m | \u001b[0m0.5805   \u001b[0m | \u001b[0m0.1283   \u001b[0m |\n",
      "| \u001b[0m48       \u001b[0m | \u001b[0m0.9429   \u001b[0m | \u001b[0m0.2254   \u001b[0m | \u001b[0m0.6479   \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
      "| \u001b[95m49       \u001b[0m | \u001b[95m0.9445   \u001b[0m | \u001b[95m0.05445  \u001b[0m | \u001b[95m0.6703   \u001b[0m | \u001b[95m0.07302  \u001b[0m |\n",
      "| \u001b[0m50       \u001b[0m | \u001b[0m-1.0     \u001b[0m | \u001b[0m0.1434   \u001b[0m | \u001b[0m0.8972   \u001b[0m | \u001b[0m0.7741   \u001b[0m |\n",
      "| \u001b[0m51       \u001b[0m | \u001b[0m0.7041   \u001b[0m | \u001b[0m0.004259 \u001b[0m | \u001b[0m0.4694   \u001b[0m | \u001b[0m0.3114   \u001b[0m |\n",
      "| \u001b[0m52       \u001b[0m | \u001b[0m0.9412   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.3993   \u001b[0m | \u001b[0m0.06158  \u001b[0m |\n",
      "| \u001b[0m53       \u001b[0m | \u001b[0m0.3354   \u001b[0m | \u001b[0m0.496    \u001b[0m | \u001b[0m0.004628 \u001b[0m | \u001b[0m0.002223 \u001b[0m |\n",
      "| \u001b[0m54       \u001b[0m | \u001b[0m-1.0     \u001b[0m | \u001b[0m0.5123   \u001b[0m | \u001b[0m0.8645   \u001b[0m | \u001b[0m0.876    \u001b[0m |\n",
      "| \u001b[0m55       \u001b[0m | \u001b[0m0.6766   \u001b[0m | \u001b[0m0.5628   \u001b[0m | \u001b[0m0.175    \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
      "| \u001b[0m56       \u001b[0m | \u001b[0m0.6607   \u001b[0m | \u001b[0m0.4046   \u001b[0m | \u001b[0m0.1197   \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
      "| \u001b[0m57       \u001b[0m | \u001b[0m0.4442   \u001b[0m | \u001b[0m0.5375   \u001b[0m | \u001b[0m0.07835  \u001b[0m | \u001b[0m0.1022   \u001b[0m |\n",
      "| \u001b[0m58       \u001b[0m | \u001b[0m-1.0     \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.4932   \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "| \u001b[0m59       \u001b[0m | \u001b[0m-1.0     \u001b[0m | \u001b[0m0.3535   \u001b[0m | \u001b[0m0.4041   \u001b[0m | \u001b[0m0.3597   \u001b[0m |\n",
      "| \u001b[0m60       \u001b[0m | \u001b[0m0.4802   \u001b[0m | \u001b[0m0.2089   \u001b[0m | \u001b[0m0.157    \u001b[0m | \u001b[0m0.492    \u001b[0m |\n",
      "| \u001b[0m61       \u001b[0m | \u001b[0m0.6893   \u001b[0m | \u001b[0m0.1428   \u001b[0m | \u001b[0m0.1751   \u001b[0m | \u001b[0m0.1382   \u001b[0m |\n",
      "| \u001b[0m62       \u001b[0m | \u001b[0m-1.0     \u001b[0m | \u001b[0m0.3124   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "| \u001b[0m63       \u001b[0m | \u001b[0m0.4677   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.1458   \u001b[0m | \u001b[0m0.6361   \u001b[0m |\n",
      "| \u001b[0m64       \u001b[0m | \u001b[0m-1.0     \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
      "| \u001b[0m65       \u001b[0m | \u001b[0m-1.0     \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.5201   \u001b[0m | \u001b[0m0.5326   \u001b[0m |\n",
      "| \u001b[0m66       \u001b[0m | \u001b[0m0.9385   \u001b[0m | \u001b[0m0.1375   \u001b[0m | \u001b[0m0.309    \u001b[0m | \u001b[0m0.0653   \u001b[0m |\n",
      "| \u001b[0m67       \u001b[0m | \u001b[0m0.8576   \u001b[0m | \u001b[0m0.1707   \u001b[0m | \u001b[0m0.421    \u001b[0m | \u001b[0m0.2146   \u001b[0m |\n",
      "| \u001b[0m68       \u001b[0m | \u001b[0m-1.0     \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "| \u001b[0m69       \u001b[0m | \u001b[0m0.9397   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.773    \u001b[0m | \u001b[0m0.1459   \u001b[0m |\n",
      "| \u001b[0m70       \u001b[0m | \u001b[0m-1.0     \u001b[0m | \u001b[0m0.04325  \u001b[0m | \u001b[0m0.6518   \u001b[0m | \u001b[0m0.3084   \u001b[0m |\n",
      "| \u001b[0m71       \u001b[0m | \u001b[0m-1.0     \u001b[0m | \u001b[0m0.02115  \u001b[0m | \u001b[0m0.9999   \u001b[0m | \u001b[0m0.3031   \u001b[0m |\n",
      "| \u001b[0m72       \u001b[0m | \u001b[0m0.9429   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.8307   \u001b[0m | \u001b[0m0.0455   \u001b[0m |\n",
      "| \u001b[0m73       \u001b[0m | \u001b[0m0.5834   \u001b[0m | \u001b[0m0.01235  \u001b[0m | \u001b[0m0.3309   \u001b[0m | \u001b[0m0.3224   \u001b[0m |\n",
      "| \u001b[0m74       \u001b[0m | \u001b[0m0.5282   \u001b[0m | \u001b[0m0.8121   \u001b[0m | \u001b[0m0.1488   \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
      "| \u001b[0m75       \u001b[0m | \u001b[0m0.9443   \u001b[0m | \u001b[0m0.1088   \u001b[0m | \u001b[0m0.7798   \u001b[0m | \u001b[0m0.06136  \u001b[0m |\n",
      "| \u001b[0m76       \u001b[0m | \u001b[0m-1.0     \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.1866   \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
      "| \u001b[0m77       \u001b[0m | \u001b[0m0.2441   \u001b[0m | \u001b[0m0.7981   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
      "| \u001b[0m78       \u001b[0m | \u001b[0m-1.0     \u001b[0m | \u001b[0m0.5793   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
      "| \u001b[0m79       \u001b[0m | \u001b[0m0.1471   \u001b[0m | \u001b[0m0.1125   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.6372   \u001b[0m |\n",
      "| \u001b[0m80       \u001b[0m | \u001b[0m0.7345   \u001b[0m | \u001b[0m0.2363   \u001b[0m | \u001b[0m0.2771   \u001b[0m | \u001b[0m0.1957   \u001b[0m |\n",
      "| \u001b[0m81       \u001b[0m | \u001b[0m0.941    \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.1715   \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
      "| \u001b[0m82       \u001b[0m | \u001b[0m-1.0     \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.4383   \u001b[0m |\n",
      "| \u001b[0m83       \u001b[0m | \u001b[0m0.8941   \u001b[0m | \u001b[0m0.0006637\u001b[0m | \u001b[0m0.4264   \u001b[0m | \u001b[0m0.1831   \u001b[0m |\n",
      "| \u001b[0m84       \u001b[0m | \u001b[0m0.9426   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.7532   \u001b[0m | \u001b[0m0.07394  \u001b[0m |\n",
      "| \u001b[0m85       \u001b[0m | \u001b[0m0.9139   \u001b[0m | \u001b[0m0.3987   \u001b[0m | \u001b[0m0.3732   \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
      "| \u001b[0m86       \u001b[0m | \u001b[0m0.4544   \u001b[0m | \u001b[0m0.5429   \u001b[0m | \u001b[0m0.08365  \u001b[0m | \u001b[0m0.1023   \u001b[0m |\n",
      "| \u001b[0m87       \u001b[0m | \u001b[0m-1.0     \u001b[0m | \u001b[0m0.6646   \u001b[0m | \u001b[0m0.634    \u001b[0m | \u001b[0m0.3589   \u001b[0m |\n",
      "| \u001b[0m88       \u001b[0m | \u001b[0m-1.0     \u001b[0m | \u001b[0m0.7533   \u001b[0m | \u001b[0m0.1806   \u001b[0m | \u001b[0m0.1756   \u001b[0m |\n",
      "| \u001b[0m89       \u001b[0m | \u001b[0m0.2871   \u001b[0m | \u001b[0m0.1081   \u001b[0m | \u001b[0m0.01722  \u001b[0m | \u001b[0m0.5403   \u001b[0m |\n",
      "| \u001b[0m90       \u001b[0m | \u001b[0m0.9313   \u001b[0m | \u001b[0m0.3383   \u001b[0m | \u001b[0m0.5127   \u001b[0m | \u001b[0m0.1124   \u001b[0m |\n",
      "| \u001b[0m91       \u001b[0m | \u001b[0m0.9428   \u001b[0m | \u001b[0m0.1205   \u001b[0m | \u001b[0m0.7095   \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
      "| \u001b[0m92       \u001b[0m | \u001b[0m-1.0     \u001b[0m | \u001b[0m0.6415   \u001b[0m | \u001b[0m0.3318   \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "| \u001b[0m93       \u001b[0m | \u001b[0m0.9442   \u001b[0m | \u001b[0m0.07986  \u001b[0m | \u001b[0m0.2111   \u001b[0m | \u001b[0m0.008718 \u001b[0m |\n",
      "| \u001b[0m94       \u001b[0m | \u001b[0m-1.0     \u001b[0m | \u001b[0m0.3506   \u001b[0m | \u001b[0m0.6743   \u001b[0m | \u001b[0m0.005335 \u001b[0m |\n",
      "| \u001b[0m95       \u001b[0m | \u001b[0m0.9358   \u001b[0m | \u001b[0m0.3142   \u001b[0m | \u001b[0m0.4677   \u001b[0m | \u001b[0m0.0387   \u001b[0m |\n",
      "| \u001b[0m96       \u001b[0m | \u001b[0m0.2411   \u001b[0m | \u001b[0m0.1366   \u001b[0m | \u001b[0m0.0009448\u001b[0m | \u001b[0m0.2881   \u001b[0m |\n",
      "| \u001b[0m97       \u001b[0m | \u001b[0m-1.0     \u001b[0m | \u001b[0m0.4609   \u001b[0m | \u001b[0m0.9918   \u001b[0m | \u001b[0m0.9687   \u001b[0m |\n",
      "| \u001b[0m98       \u001b[0m | \u001b[0m0.8167   \u001b[0m | \u001b[0m0.4433   \u001b[0m | \u001b[0m0.3001   \u001b[0m | \u001b[0m0.1364   \u001b[0m |\n",
      "| \u001b[0m99       \u001b[0m | \u001b[0m0.9442   \u001b[0m | \u001b[0m0.2091   \u001b[0m | \u001b[0m0.5616   \u001b[0m | \u001b[0m0.02507  \u001b[0m |\n",
      "| \u001b[0m100      \u001b[0m | \u001b[0m-1.0     \u001b[0m | \u001b[0m0.003158 \u001b[0m | \u001b[0m0.3426   \u001b[0m | \u001b[0m0.6888   \u001b[0m |\n",
      "| \u001b[0m101      \u001b[0m | \u001b[0m0.5013   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.1805   \u001b[0m | \u001b[0m0.4577   \u001b[0m |\n",
      "| \u001b[0m102      \u001b[0m | \u001b[0m0.3518   \u001b[0m | \u001b[0m0.4951   \u001b[0m | \u001b[0m0.01275  \u001b[0m | \u001b[0m0.002117 \u001b[0m |\n",
      "| \u001b[0m103      \u001b[0m | \u001b[0m0.2145   \u001b[0m | \u001b[0m0.3698   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.07874  \u001b[0m |\n",
      "| \u001b[0m104      \u001b[0m | \u001b[0m0.8267   \u001b[0m | \u001b[0m0.479    \u001b[0m | \u001b[0m0.2459   \u001b[0m | \u001b[0m0.02583  \u001b[0m |\n",
      "| \u001b[0m105      \u001b[0m | \u001b[0m-1.0     \u001b[0m | \u001b[0m0.8294   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.6798   \u001b[0m |\n",
      "=============================================================\n"
     ]
    }
   ],
   "source": [
    "params_bayes = {'w1': (0,1),\n",
    "          'w2': (0,1),\n",
    "           'w3':(0,1) }\n",
    "optimizer = BayesianOptimization(f = internal_method,\n",
    "                                pbounds = params_bayes,\n",
    "                                random_state = 7,\n",
    "\t\t\t\t                verbose=2)\n",
    "optimizer.maximize(init_points=5, n_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_value=optimizer.max['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05445067852011942"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_value['w1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.46315054139015016, 0.43500000000000033)"
      ]
     },
     "execution_count": 608,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions=np.array(submission_combined[genre2idx.keys()])\n",
    "threshold=0.01\n",
    "maxvalue=0\n",
    "bestT=0\n",
    "for t in range(990):\n",
    "    predictions_new=(predictions>=threshold).astype(int)\n",
    "    tempval=f1_score(y_test,predictions_new,average=\"micro\")\n",
    "    if maxvalue< tempval:\n",
    "        maxvalue=tempval\n",
    "        bestT=threshold\n",
    "    threshold+=0.001\n",
    "maxvalue,bestT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5593050193050193"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_prediction__trainids = np.argsort(-submission_combined[genre2idx.keys()],axis=1)\n",
    "top_10_prediction_trainids = sorted_prediction__trainids[:,:5]\n",
    "def get_column_names_train(row):\n",
    "    return list(vectors_labels.columns[row == 1])\n",
    "vectors_labels_new=vectors_labels.apply(get_column_names_train,axis=1).tolist()\n",
    "mapk(vectors_labels_new,top_10_prediction_trainids,k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2=ModelByTitle(movies_train)\n",
    "model2.preprocess_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 1ms/step\n",
      "           0         1         2         3         4         5         6   \\\n",
      "0    0.000996  0.000336  0.023852  0.004608  0.004325  0.898872  0.026702   \n",
      "1    0.025985  0.019138  0.020980  0.006205  0.017233  0.632488  0.020173   \n",
      "2    0.000005  0.001509  0.000002  0.999687  0.013229  0.000322  0.000223   \n",
      "3    0.006906  0.062737  0.000819  0.031431  0.016090  0.042370  0.005411   \n",
      "4    0.006996  0.010060  0.001840  0.002219  0.002843  0.289518  0.010110   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "772  0.020495  0.453637  0.001125  0.031424  0.044346  0.000386  0.002457   \n",
      "773  0.044798  0.010418  0.014248  0.008039  0.021369  0.038846  0.019337   \n",
      "774  0.000912  0.000125  0.000534  0.000107  0.000222  0.631757  0.001095   \n",
      "775  0.067628  0.095743  0.011778  0.013907  0.023421  0.170064  0.019597   \n",
      "776  0.002932  0.065224  0.000471  0.666318  0.023094  0.039309  0.003314   \n",
      "\n",
      "           7         8         9             10        11        12        13  \\\n",
      "0    0.036078  0.000969  0.137837  3.613591e-02  0.002658  0.014669  0.210625   \n",
      "1    0.061327  0.008173  0.027885  6.490345e-02  0.095085  0.031452  0.085587   \n",
      "2    0.000005  0.000046  0.000003  6.697421e-07  0.000329  0.000151  0.000061   \n",
      "3    0.002494  0.003604  0.000576  2.662828e-02  0.190030  0.005149  0.004331   \n",
      "4    0.003943  0.001921  0.002471  3.221350e-01  0.493857  0.008405  0.021830   \n",
      "..        ...       ...       ...           ...       ...       ...       ...   \n",
      "772  0.019385  0.005337  0.000144  9.228280e-04  0.338908  0.003872  0.000386   \n",
      "773  0.078338  0.004134  0.004523  1.921457e-03  0.537479  0.016002  0.009743   \n",
      "774  0.002266  0.000062  0.000461  8.063994e-04  0.435347  0.000570  0.004489   \n",
      "775  0.028771  0.016139  0.007669  9.791850e-02  0.452937  0.027922  0.028606   \n",
      "776  0.001219  0.003152  0.000423  3.335789e-03  0.026961  0.005061  0.003672   \n",
      "\n",
      "           14        15        16        17  \n",
      "0    0.002159  0.001423  0.003047  0.544289  \n",
      "1    0.053125  0.012380  0.019448  0.075795  \n",
      "2    0.000015  0.000027  0.000090  0.000005  \n",
      "3    0.006425  0.009592  0.006261  0.000839  \n",
      "4    0.004898  0.007530  0.012240  0.005121  \n",
      "..        ...       ...       ...       ...  \n",
      "772  0.463338  0.031934  0.059565  0.000186  \n",
      "773  0.577831  0.016081  0.081491  0.020262  \n",
      "774  0.000507  0.000191  0.000185  0.018852  \n",
      "775  0.080137  0.043276  0.049208  0.014821  \n",
      "776  0.003037  0.004371  0.005133  0.000536  \n",
      "\n",
      "[777 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "model2.predict(movies_test)\n",
    "print(pd.DataFrame(model2.test_neural))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5649435149435149\n"
     ]
    }
   ],
   "source": [
    "model2.evaluate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5349006149006149"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural=load_model('./trained_model_params/neuralbytitle.h5', custom_objects={'f1_m': neural_metrics.f1_m, \n",
    "                                                               'precision_m': neural_metrics.precision_m, \n",
    "                                                               'recall_m': neural_metrics.recall_m})\n",
    "submission_neural = neural.predict(x_test)\n",
    "sorted_prediction__trainids = np.argsort(-pd.DataFrame(submission_neural),axis=1)\n",
    "top_10_prediction_trainids = sorted_prediction__trainids[:,:5]\n",
    "def get_column_names_train(row):\n",
    "    return list(vectors_labels.columns[row == 1])\n",
    "vectors_labels_new=vectors_labels.apply(get_column_names_train,axis=1).tolist()\n",
    "mapk(vectors_labels_new,top_10_prediction_trainids,k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import average_precision_score\n",
    "# sorted_indices = np.argsort(predictions[0])[::-1]\n",
    "# top_k_indices = sorted_indices[:3]\n",
    "# y_true_k = np.array(y_test[0])[top_k_indices]\n",
    "# y_score_k = np.array(predictions[0])[top_k_indices]\n",
    "# y_score_k=np.ones(y_score_k.shape[0])\n",
    "# map_at_k_instance = average_precision_score(y_true_k, y_score_k)\n",
    "# print(y_true_k,\"--\",y_score_k)\n",
    "# map_at_k_instance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_score=predictions.copy()\n",
    "# sorted_indices = np.argsort(y_score[0])[::-1]\n",
    "# top_k_indices = sorted_indices[:3]\n",
    "# y_true_k = np.array(y_test[0])[top_k_indices]\n",
    "# y_score_k = np.array(y_score[0])[top_k_indices]\n",
    "# y_score[0]=[0 if i not in top_k_indices else 1 for i in range(18) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Crime</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Western</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Action</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>War</th>\n",
       "      <th>Children's</th>\n",
       "      <th>movieid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>3.870663e-07</td>\n",
       "      <td>5.588573e-03</td>\n",
       "      <td>4.905767e-01</td>\n",
       "      <td>9.714553e-01</td>\n",
       "      <td>0.759675</td>\n",
       "      <td>4.993133e-07</td>\n",
       "      <td>5.294202e-08</td>\n",
       "      <td>0.001620</td>\n",
       "      <td>6.519864e-03</td>\n",
       "      <td>2.471888e-10</td>\n",
       "      <td>1.180897e-09</td>\n",
       "      <td>0.157409</td>\n",
       "      <td>8.858831e-09</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>7.059093e-06</td>\n",
       "      <td>2.320997e-08</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>7.646935e-02</td>\n",
       "      <td>7.114165e-01</td>\n",
       "      <td>7.515992e-02</td>\n",
       "      <td>7.919439e-01</td>\n",
       "      <td>0.395226</td>\n",
       "      <td>2.943085e-04</td>\n",
       "      <td>2.400148e-05</td>\n",
       "      <td>0.028851</td>\n",
       "      <td>2.953669e-01</td>\n",
       "      <td>2.462466e-06</td>\n",
       "      <td>3.286522e-05</td>\n",
       "      <td>0.057991</td>\n",
       "      <td>3.826486e-05</td>\n",
       "      <td>0.001347</td>\n",
       "      <td>5.744367e-02</td>\n",
       "      <td>2.386100e-04</td>\n",
       "      <td>0.010462</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1392</th>\n",
       "      <td>2.703023e-09</td>\n",
       "      <td>6.300670e-08</td>\n",
       "      <td>2.244248e-07</td>\n",
       "      <td>1.101623e-04</td>\n",
       "      <td>0.998038</td>\n",
       "      <td>2.711532e-09</td>\n",
       "      <td>7.601015e-08</td>\n",
       "      <td>0.025326</td>\n",
       "      <td>2.474137e-06</td>\n",
       "      <td>4.268960e-15</td>\n",
       "      <td>2.123879e-12</td>\n",
       "      <td>0.007880</td>\n",
       "      <td>1.670983e-12</td>\n",
       "      <td>0.925919</td>\n",
       "      <td>9.657675e-09</td>\n",
       "      <td>4.077637e-15</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>6.709979e-06</td>\n",
       "      <td>2.027540e-06</td>\n",
       "      <td>9.660791e-08</td>\n",
       "      <td>3.736447e-06</td>\n",
       "      <td>0.724210</td>\n",
       "      <td>1.777470e-04</td>\n",
       "      <td>4.004234e-05</td>\n",
       "      <td>0.900848</td>\n",
       "      <td>1.284414e-06</td>\n",
       "      <td>2.511105e-07</td>\n",
       "      <td>2.761061e-08</td>\n",
       "      <td>0.001773</td>\n",
       "      <td>1.778810e-05</td>\n",
       "      <td>0.198830</td>\n",
       "      <td>1.078945e-06</td>\n",
       "      <td>1.205497e-06</td>\n",
       "      <td>0.007763</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>8.953288e-06</td>\n",
       "      <td>7.385816e-06</td>\n",
       "      <td>4.384601e-07</td>\n",
       "      <td>6.189873e-05</td>\n",
       "      <td>0.983944</td>\n",
       "      <td>8.971808e-07</td>\n",
       "      <td>3.012010e-07</td>\n",
       "      <td>0.003301</td>\n",
       "      <td>3.472895e-06</td>\n",
       "      <td>9.501677e-12</td>\n",
       "      <td>1.861406e-08</td>\n",
       "      <td>0.001732</td>\n",
       "      <td>6.593625e-10</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>6.486861e-06</td>\n",
       "      <td>4.955769e-10</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2060</th>\n",
       "      <td>1.828408e-03</td>\n",
       "      <td>5.222157e-01</td>\n",
       "      <td>4.428852e-01</td>\n",
       "      <td>9.723589e-01</td>\n",
       "      <td>0.431562</td>\n",
       "      <td>3.014984e-05</td>\n",
       "      <td>2.223346e-07</td>\n",
       "      <td>0.002530</td>\n",
       "      <td>2.268593e-01</td>\n",
       "      <td>7.400577e-08</td>\n",
       "      <td>2.561600e-07</td>\n",
       "      <td>0.112610</td>\n",
       "      <td>1.732802e-06</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>3.686572e-03</td>\n",
       "      <td>3.434829e-05</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>3945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2090</th>\n",
       "      <td>5.709537e-04</td>\n",
       "      <td>1.113671e-04</td>\n",
       "      <td>3.283138e-07</td>\n",
       "      <td>2.886468e-06</td>\n",
       "      <td>0.069801</td>\n",
       "      <td>3.842392e-04</td>\n",
       "      <td>6.744616e-07</td>\n",
       "      <td>0.001841</td>\n",
       "      <td>1.744801e-06</td>\n",
       "      <td>3.459906e-07</td>\n",
       "      <td>5.272710e-06</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>4.058358e-06</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>2.639322e-04</td>\n",
       "      <td>1.360133e-04</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>3947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2210</th>\n",
       "      <td>9.325756e-08</td>\n",
       "      <td>1.222899e-07</td>\n",
       "      <td>5.033113e-09</td>\n",
       "      <td>5.860165e-06</td>\n",
       "      <td>0.998683</td>\n",
       "      <td>1.283153e-09</td>\n",
       "      <td>5.818299e-10</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>5.115896e-08</td>\n",
       "      <td>5.768047e-17</td>\n",
       "      <td>9.404320e-11</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>1.775717e-14</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.760225e-07</td>\n",
       "      <td>2.757559e-14</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>3948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>1.977016e-06</td>\n",
       "      <td>1.358552e-07</td>\n",
       "      <td>1.562951e-10</td>\n",
       "      <td>2.349096e-08</td>\n",
       "      <td>0.223578</td>\n",
       "      <td>1.670921e-04</td>\n",
       "      <td>5.517305e-06</td>\n",
       "      <td>0.990480</td>\n",
       "      <td>9.491729e-09</td>\n",
       "      <td>1.016626e-07</td>\n",
       "      <td>2.456722e-09</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>3.429307e-05</td>\n",
       "      <td>0.016114</td>\n",
       "      <td>9.864890e-08</td>\n",
       "      <td>5.276322e-06</td>\n",
       "      <td>0.006156</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>3949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>3.799998e-05</td>\n",
       "      <td>1.369495e-06</td>\n",
       "      <td>5.406476e-11</td>\n",
       "      <td>1.026095e-08</td>\n",
       "      <td>0.017750</td>\n",
       "      <td>1.084603e-03</td>\n",
       "      <td>4.111282e-06</td>\n",
       "      <td>0.993474</td>\n",
       "      <td>1.008058e-08</td>\n",
       "      <td>1.564598e-06</td>\n",
       "      <td>1.837668e-08</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>5.139986e-04</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>8.700396e-07</td>\n",
       "      <td>4.247465e-04</td>\n",
       "      <td>0.011929</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>3950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3106 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Crime      Thriller       Fantasy        Horror    Sci-Fi  \\\n",
       "838   3.870663e-07  5.588573e-03  4.905767e-01  9.714553e-01  0.759675   \n",
       "278   7.646935e-02  7.114165e-01  7.515992e-02  7.919439e-01  0.395226   \n",
       "1392  2.703023e-09  6.300670e-08  2.244248e-07  1.101623e-04  0.998038   \n",
       "339   6.709979e-06  2.027540e-06  9.660791e-08  3.736447e-06  0.724210   \n",
       "844   8.953288e-06  7.385816e-06  4.384601e-07  6.189873e-05  0.983944   \n",
       "...            ...           ...           ...           ...       ...   \n",
       "2060  1.828408e-03  5.222157e-01  4.428852e-01  9.723589e-01  0.431562   \n",
       "2090  5.709537e-04  1.113671e-04  3.283138e-07  2.886468e-06  0.069801   \n",
       "2210  9.325756e-08  1.222899e-07  5.033113e-09  5.860165e-06  0.998683   \n",
       "1197  1.977016e-06  1.358552e-07  1.562951e-10  2.349096e-08  0.223578   \n",
       "1240  3.799998e-05  1.369495e-06  5.406476e-11  1.026095e-08  0.017750   \n",
       "\n",
       "            Comedy   Documentary  Adventure     Film-Noir     Animation  \\\n",
       "838   4.993133e-07  5.294202e-08   0.001620  6.519864e-03  2.471888e-10   \n",
       "278   2.943085e-04  2.400148e-05   0.028851  2.953669e-01  2.462466e-06   \n",
       "1392  2.711532e-09  7.601015e-08   0.025326  2.474137e-06  4.268960e-15   \n",
       "339   1.777470e-04  4.004234e-05   0.900848  1.284414e-06  2.511105e-07   \n",
       "844   8.971808e-07  3.012010e-07   0.003301  3.472895e-06  9.501677e-12   \n",
       "...            ...           ...        ...           ...           ...   \n",
       "2060  3.014984e-05  2.223346e-07   0.002530  2.268593e-01  7.400577e-08   \n",
       "2090  3.842392e-04  6.744616e-07   0.001841  1.744801e-06  3.459906e-07   \n",
       "2210  1.283153e-09  5.818299e-10   0.000045  5.115896e-08  5.768047e-17   \n",
       "1197  1.670921e-04  5.517305e-06   0.990480  9.491729e-09  1.016626e-07   \n",
       "1240  1.084603e-03  4.111282e-06   0.993474  1.008058e-08  1.564598e-06   \n",
       "\n",
       "           Romance     Drama       Western   Musical        Action  \\\n",
       "838   1.180897e-09  0.157409  8.858831e-09  0.000003  7.059093e-06   \n",
       "278   3.286522e-05  0.057991  3.826486e-05  0.001347  5.744367e-02   \n",
       "1392  2.123879e-12  0.007880  1.670983e-12  0.925919  9.657675e-09   \n",
       "339   2.761061e-08  0.001773  1.778810e-05  0.198830  1.078945e-06   \n",
       "844   1.861406e-08  0.001732  6.593625e-10  0.000575  6.486861e-06   \n",
       "...            ...       ...           ...       ...           ...   \n",
       "2060  2.561600e-07  0.112610  1.732802e-06  0.000028  3.686572e-03   \n",
       "2090  5.272710e-06  0.000015  4.058358e-06  0.000007  2.639322e-04   \n",
       "2210  9.404320e-11  0.000235  1.775717e-14  0.000003  1.760225e-07   \n",
       "1197  2.456722e-09  0.000057  3.429307e-05  0.016114  9.864890e-08   \n",
       "1240  1.837668e-08  0.000006  5.139986e-04  0.002041  8.700396e-07   \n",
       "\n",
       "           Mystery       War  Children's  movieid  \n",
       "838   2.320997e-08  0.000005    0.000002        1  \n",
       "278   2.386100e-04  0.010462    0.001200        2  \n",
       "1392  4.077637e-15  0.000075    0.000042        3  \n",
       "339   1.205497e-06  0.007763    0.000331        4  \n",
       "844   4.955769e-10  0.000130    0.000100        5  \n",
       "...            ...       ...         ...      ...  \n",
       "2060  3.434829e-05  0.000162    0.000019     3945  \n",
       "2090  1.360133e-04  0.000074    0.000008     3947  \n",
       "2210  2.757559e-14  0.000002    0.000003     3948  \n",
       "1197  5.276322e-06  0.006156    0.000029     3949  \n",
       "1240  4.247465e-04  0.011929    0.000013     3950  \n",
       "\n",
       "[3106 rows x 19 columns]"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel='rbf', C=0.3, gamma=1, shrinking=False, probability=True)\n",
    "for label in genre2idx.keys():\n",
    "    print('... Processing {}'.format(\"Crime\"))\n",
    "    y = data[label]\n",
    "    # train the model \n",
    "    clf.fit(x_train, y)\n",
    "    # compute the training accuracy\n",
    "    y_pred_X = clf.predict(x_train)\n",
    "    print('Training accuracy is {}'.format(accuracy_score(y, y_pred_X)))\n",
    "    # compute the predicted probabilities for x_test\n",
    "    test_y_prob = clf.predict_proba(x_test)[:,1]\n",
    "    submission_binary[label] = test_y_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HyperParameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearch (Dont need to run again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'C': [0.0001, 0.001, 0.01, 0.1, 1, 10],\n",
    "          'gamma': [0.00001, 0.0001, 0.001, 0.01,0.1],\n",
    "          'kernel':['linear','rbf','poly'] }\n",
    "grid_clf = GridSearchCV(SVC(), params,cv=10)\n",
    "\n",
    "#Fit the data with the best possible parameters\n",
    "grid_clf.fit(x_train, data[\"Crime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "def internal_method(C,gamma):\n",
    "    svm_model=SVC(kernel='rbf', C=C, gamma=gamma, probability=True)\n",
    "    multilabel_classifier = MultiOutputClassifier(svm_model, n_jobs=-1)\n",
    "    multilabel_classifier = multilabel_classifier.fit(x_train, y_train)\n",
    "\n",
    "    return cross_val_score(multilabel_classifier, x_train, y_train, cv=5, scoring='f1_micro').mean()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_bayes = {'C': (1e-5,2),\n",
    "          'gamma': (1e-4,2) }\n",
    "optimizer = BayesianOptimization(f = internal_method,\n",
    "                                pbounds = params_bayes,\n",
    "                                random_state = 7,\n",
    "\t\t\t\t                verbose=2)\n",
    "optimizer.maximize(init_points=10, n_iter=5)\n",
    "optimal_params = optimizer.max['params']\n",
    "optimal_C = optimal_params['C']\n",
    "optimal_gamma = optimal_params['gamma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_C,optimal_gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearnex import patch_sklearn, config_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_SVM = pd.read_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Processing Crime\n",
      "Training accuracy is 0.983050847457627\n"
     ]
    }
   ],
   "source": [
    "patch_sklearn()\n",
    "clf = SVC(kernel='rbf', C=1.94, gamma=0.5385, probability=True)\n",
    "print('... Processing {}'.format(\"Crime\"))\n",
    "y = data[\"Crime\"]\n",
    "# train the model\n",
    "with config_context(target_offload=\"gpu:0\"): \n",
    "    clf.fit(x_train, y)\n",
    "# compute the training accuracy\n",
    "y_pred_X = clf.predict(x_train)\n",
    "print('Training accuracy is {}'.format(f1_score(y, y_pred_X)))\n",
    "# compute the predicted probabilities for x_test\n",
    "test_y_prob = clf.predict_proba(x_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Processing Drama\n",
      "Training accuracy is 0.9991724137931035\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='rbf', C=1.956, gamma=0.5385, probability=True)\n",
    "smote=BorderlineSMOTE(random_state=10,k_neighbors=10)\n",
    "label=\"Drama\"\n",
    "smote_x_train,smote_y_train=smote.fit_resample(x_train,data[label])\n",
    "print('... Processing {}'.format(label))\n",
    "y = smote_y_train\n",
    "# train the model \n",
    "clf.fit(smote_x_train, y)\n",
    "# compute the training accuracy\n",
    "y_pred_X = clf.predict(smote_x_train)\n",
    "print('Training accuracy is {}'.format(f1_score(y, y_pred_X)))\n",
    "# compute the predicted probabilities for x_test\n",
    "test_y_prob = clf.predict_proba(x_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_X = clf.predict(smote_x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.09404388714733543, 0.3950000000000003)"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold=0.01\n",
    "maxvalue=0\n",
    "bestT=0\n",
    "for t in range(990):\n",
    "    test_y_prob_new=(test_y_prob>=threshold).astype(int)\n",
    "    tempval=f1_score(data_test[\"Crime\"],test_y_prob_new)\n",
    "    if maxvalue< tempval:\n",
    "        maxvalue=tempval\n",
    "        bestT=threshold\n",
    "    threshold+=0.001\n",
    "maxvalue,bestT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "378  0\n",
       "379  0\n",
       "380  0\n",
       "381  0\n",
       "382  0\n",
       "383  0\n",
       "384  0\n",
       "385  0\n",
       "386  1\n",
       "387  0\n",
       "388  0\n",
       "389  0\n",
       "390  0\n",
       "391  0\n",
       "392  0\n",
       "393  0\n",
       "394  0\n",
       "395  0\n",
       "396  0\n",
       "397  0"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame((test_y_prob>=0.271).astype(int)).iloc[21*18:21*18+20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Crime</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Western</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Action</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>War</th>\n",
       "      <th>Children's</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Crime  Thriller  Fantasy  Horror  Sci-Fi  Comedy  Documentary  Adventure  \\\n",
       "378    0.0       0.0      0.0     0.0     0.0     1.0          0.0        0.0   \n",
       "379    0.0       0.0      0.0     1.0     0.0     1.0          0.0        0.0   \n",
       "380    0.0       0.0      0.0     0.0     1.0     0.0          0.0        0.0   \n",
       "381    0.0       1.0      0.0     0.0     0.0     0.0          0.0        0.0   \n",
       "382    0.0       1.0      0.0     0.0     0.0     0.0          0.0        0.0   \n",
       "383    0.0       0.0      0.0     0.0     0.0     0.0          0.0        0.0   \n",
       "384    1.0       0.0      0.0     0.0     0.0     0.0          0.0        0.0   \n",
       "385    0.0       0.0      0.0     0.0     1.0     1.0          0.0        0.0   \n",
       "386    0.0       0.0      0.0     0.0     0.0     1.0          0.0        0.0   \n",
       "387    0.0       0.0      0.0     0.0     0.0     1.0          0.0        0.0   \n",
       "388    0.0       0.0      0.0     0.0     0.0     1.0          0.0        0.0   \n",
       "389    0.0       0.0      0.0     0.0     0.0     0.0          0.0        0.0   \n",
       "390    1.0       0.0      0.0     0.0     0.0     0.0          0.0        0.0   \n",
       "391    0.0       0.0      0.0     0.0     0.0     1.0          0.0        0.0   \n",
       "392    0.0       0.0      0.0     0.0     0.0     0.0          0.0        0.0   \n",
       "393    0.0       0.0      0.0     0.0     0.0     0.0          0.0        0.0   \n",
       "394    0.0       0.0      0.0     0.0     0.0     1.0          0.0        0.0   \n",
       "395    0.0       0.0      0.0     0.0     1.0     1.0          0.0        0.0   \n",
       "396    0.0       0.0      0.0     0.0     0.0     0.0          0.0        0.0   \n",
       "397    0.0       0.0      0.0     0.0     0.0     1.0          0.0        0.0   \n",
       "\n",
       "     Film-Noir  Animation  Romance  Drama  Western  Musical  Action  Mystery  \\\n",
       "378        0.0        1.0      1.0    0.0      0.0      1.0     0.0      0.0   \n",
       "379        0.0        0.0      0.0    0.0      0.0      0.0     0.0      0.0   \n",
       "380        0.0        0.0      0.0    1.0      0.0      0.0     0.0      0.0   \n",
       "381        0.0        0.0      0.0    0.0      0.0      0.0     1.0      0.0   \n",
       "382        0.0        0.0      0.0    1.0      0.0      0.0     0.0      0.0   \n",
       "383        0.0        0.0      0.0    1.0      0.0      0.0     0.0      0.0   \n",
       "384        0.0        0.0      0.0    1.0      0.0      0.0     0.0      0.0   \n",
       "385        0.0        0.0      0.0    0.0      0.0      0.0     0.0      0.0   \n",
       "386        0.0        0.0      0.0    0.0      0.0      0.0     1.0      0.0   \n",
       "387        0.0        0.0      0.0    1.0      0.0      0.0     0.0      0.0   \n",
       "388        0.0        0.0      0.0    0.0      0.0      0.0     0.0      0.0   \n",
       "389        0.0        0.0      0.0    1.0      0.0      0.0     0.0      0.0   \n",
       "390        0.0        0.0      0.0    1.0      0.0      0.0     0.0      0.0   \n",
       "391        0.0        0.0      0.0    0.0      0.0      0.0     0.0      0.0   \n",
       "392        0.0        0.0      0.0    1.0      0.0      0.0     0.0      0.0   \n",
       "393        0.0        0.0      1.0    1.0      0.0      0.0     0.0      0.0   \n",
       "394        0.0        0.0      1.0    0.0      0.0      0.0     0.0      0.0   \n",
       "395        0.0        0.0      0.0    0.0      1.0      0.0     0.0      0.0   \n",
       "396        0.0        0.0      0.0    1.0      0.0      0.0     0.0      0.0   \n",
       "397        0.0        0.0      0.0    0.0      0.0      0.0     0.0      0.0   \n",
       "\n",
       "     War  Children's  \n",
       "378  0.0         1.0  \n",
       "379  0.0         0.0  \n",
       "380  0.0         0.0  \n",
       "381  0.0         0.0  \n",
       "382  0.0         0.0  \n",
       "383  0.0         0.0  \n",
       "384  0.0         0.0  \n",
       "385  0.0         0.0  \n",
       "386  0.0         0.0  \n",
       "387  0.0         0.0  \n",
       "388  0.0         1.0  \n",
       "389  0.0         0.0  \n",
       "390  0.0         0.0  \n",
       "391  0.0         0.0  \n",
       "392  0.0         0.0  \n",
       "393  0.0         0.0  \n",
       "394  0.0         0.0  \n",
       "395  0.0         0.0  \n",
       "396  0.0         0.0  \n",
       "397  0.0         0.0  "
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test[genre2idx.keys()].iloc[21*18:21*18+20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_binary.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Crime\\tThriller\\tFantasy\\tHorror\\tSci-Fi\\tComedy\\tDocumentary\\tAdventure\\tFilm-Noir\\tAnimation\\tRomance\\tDrama\\tWestern\\tMusical\\tAction\\tMystery\\tWar\\tChildren's</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Western</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Action</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>War</th>\n",
       "      <th>Children's</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.054053</td>\n",
       "      <td>0.078331</td>\n",
       "      <td>0.018728</td>\n",
       "      <td>0.052084</td>\n",
       "      <td>0.046935</td>\n",
       "      <td>0.350676</td>\n",
       "      <td>0.031112</td>\n",
       "      <td>0.094403</td>\n",
       "      <td>0.012341</td>\n",
       "      <td>0.024265</td>\n",
       "      <td>0.118971</td>\n",
       "      <td>0.386623</td>\n",
       "      <td>0.016305</td>\n",
       "      <td>0.037056</td>\n",
       "      <td>0.093012</td>\n",
       "      <td>0.025517</td>\n",
       "      <td>0.053444</td>\n",
       "      <td>0.092527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.056664</td>\n",
       "      <td>0.103570</td>\n",
       "      <td>0.019183</td>\n",
       "      <td>0.051906</td>\n",
       "      <td>0.061299</td>\n",
       "      <td>0.310440</td>\n",
       "      <td>0.029980</td>\n",
       "      <td>0.073301</td>\n",
       "      <td>0.012375</td>\n",
       "      <td>0.026629</td>\n",
       "      <td>0.116200</td>\n",
       "      <td>0.373645</td>\n",
       "      <td>0.016557</td>\n",
       "      <td>0.032931</td>\n",
       "      <td>0.107148</td>\n",
       "      <td>0.026250</td>\n",
       "      <td>0.037375</td>\n",
       "      <td>0.051292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.054093</td>\n",
       "      <td>0.075493</td>\n",
       "      <td>0.018808</td>\n",
       "      <td>0.376041</td>\n",
       "      <td>0.050614</td>\n",
       "      <td>0.277523</td>\n",
       "      <td>0.033134</td>\n",
       "      <td>0.065633</td>\n",
       "      <td>0.012336</td>\n",
       "      <td>0.026457</td>\n",
       "      <td>0.120092</td>\n",
       "      <td>0.362337</td>\n",
       "      <td>0.016434</td>\n",
       "      <td>0.032333</td>\n",
       "      <td>0.096719</td>\n",
       "      <td>0.025204</td>\n",
       "      <td>0.037982</td>\n",
       "      <td>0.052329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.059661</td>\n",
       "      <td>0.098490</td>\n",
       "      <td>0.019580</td>\n",
       "      <td>0.055874</td>\n",
       "      <td>0.056423</td>\n",
       "      <td>0.344480</td>\n",
       "      <td>0.038163</td>\n",
       "      <td>0.074960</td>\n",
       "      <td>0.012383</td>\n",
       "      <td>0.027207</td>\n",
       "      <td>0.131152</td>\n",
       "      <td>0.407442</td>\n",
       "      <td>0.016767</td>\n",
       "      <td>0.032472</td>\n",
       "      <td>0.116767</td>\n",
       "      <td>0.029274</td>\n",
       "      <td>0.038663</td>\n",
       "      <td>0.058814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.055432</td>\n",
       "      <td>0.099403</td>\n",
       "      <td>0.018943</td>\n",
       "      <td>0.070945</td>\n",
       "      <td>0.057706</td>\n",
       "      <td>0.251765</td>\n",
       "      <td>0.029747</td>\n",
       "      <td>0.066385</td>\n",
       "      <td>0.012361</td>\n",
       "      <td>0.026224</td>\n",
       "      <td>0.114059</td>\n",
       "      <td>0.485583</td>\n",
       "      <td>0.016185</td>\n",
       "      <td>0.032288</td>\n",
       "      <td>0.113561</td>\n",
       "      <td>0.027046</td>\n",
       "      <td>0.036509</td>\n",
       "      <td>0.050346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Crime\\tThriller\\tFantasy\\tHorror\\tSci-Fi\\tComedy\\tDocumentary\\tAdventure\\tFilm-Noir\\tAnimation\\tRomance\\tDrama\\tWestern\\tMusical\\tAction\\tMystery\\tWar\\tChildren's  \\\n",
       "0                                                NaN                                                                                                                   \n",
       "1                                                NaN                                                                                                                   \n",
       "2                                                NaN                                                                                                                   \n",
       "3                                                NaN                                                                                                                   \n",
       "4                                                NaN                                                                                                                   \n",
       "\n",
       "      Crime  Thriller   Fantasy    Horror    Sci-Fi    Comedy  Documentary  \\\n",
       "0  0.054053  0.078331  0.018728  0.052084  0.046935  0.350676     0.031112   \n",
       "1  0.056664  0.103570  0.019183  0.051906  0.061299  0.310440     0.029980   \n",
       "2  0.054093  0.075493  0.018808  0.376041  0.050614  0.277523     0.033134   \n",
       "3  0.059661  0.098490  0.019580  0.055874  0.056423  0.344480     0.038163   \n",
       "4  0.055432  0.099403  0.018943  0.070945  0.057706  0.251765     0.029747   \n",
       "\n",
       "   Adventure  Film-Noir  Animation   Romance     Drama   Western   Musical  \\\n",
       "0   0.094403   0.012341   0.024265  0.118971  0.386623  0.016305  0.037056   \n",
       "1   0.073301   0.012375   0.026629  0.116200  0.373645  0.016557  0.032931   \n",
       "2   0.065633   0.012336   0.026457  0.120092  0.362337  0.016434  0.032333   \n",
       "3   0.074960   0.012383   0.027207  0.131152  0.407442  0.016767  0.032472   \n",
       "4   0.066385   0.012361   0.026224  0.114059  0.485583  0.016185  0.032288   \n",
       "\n",
       "     Action   Mystery       War  Children's  \n",
       "0  0.093012  0.025517  0.053444    0.092527  \n",
       "1  0.107148  0.026250  0.037375    0.051292  \n",
       "2  0.096719  0.025204  0.037982    0.052329  \n",
       "3  0.116767  0.029274  0.038663    0.058814  \n",
       "4  0.113561  0.027046  0.036509    0.050346  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_binary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=100\n",
    "rate=0.1\n",
    "batch_size=200\n",
    "layer_size=512\n",
    "w1=nn.Parameter(3899,layer_size)\n",
    "w2=nn.Parameter(layer_size,18)\n",
    "b1=nn.Parameter(1,layer_size)\n",
    "b2=nn.Parameter(1,18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(x):\n",
    "    z1=nn.AddBias(nn.Linear(x,w1),b1)\n",
    "    a1=nn.ReLU(z1)\n",
    "    # z2=nn.AddBias(nn.Linear(a1,w2),b2) \n",
    "    # a2=nn.ReLU(z2)\n",
    "    z2=nn.AddBias(nn.Linear(a1,w2),b2) \n",
    "    yhat=z2\n",
    "    return yhat\n",
    "def get_loss(x, y):\n",
    "    return nn.SoftmaxLoss(run(x),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_validation_accuracy():\n",
    "    dev_logits = run(nn.Constant(x_test)).data\n",
    "    dev_predicted = np.argmax(dev_logits, axis=1)\n",
    "    dev_accuracy = np.mean(dev_predicted == y_test)\n",
    "    return dev_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(x_train,y_train):\n",
    "    noExamples=x_train.shape[0]\n",
    "    for _ in range(epochs):\n",
    "        start_idx=np.random.randint(noExamples)\n",
    "        end_idx=min(start_idx+batch_size,noExamples)\n",
    "        xSample=x_train[start_idx:end_idx]\n",
    "        ySample=y_train[start_idx:end_idx]\n",
    "        grad_wrt_w1,grad_wrt_w2,grad_wrt_b1,grad_wrt_b2 = nn.gradients(get_loss(nn.Constant(xSample), nn.Constant(ySample)), [w1,w2,b1,b2])\n",
    "        print(get_validation_accuracy())\n",
    "        if get_validation_accuracy()>=0.2:\n",
    "            break\n",
    "        w1.update(grad_wrt_w1,rate)\n",
    "        w2.update(grad_wrt_w2,rate)\n",
    "        b1.update(grad_wrt_b1,rate)\n",
    "        b2.update(grad_wrt_b2,rate)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.25, 0.  , 0.  , 0.  , 0.  , 0.25, 0.  , 0.25, 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.25, 0.  , 0.  , 0.  ])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "y_train_standard=normalize(y_train,norm='l1',axis=1)\n",
    "y_train_standard[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(x_train,y_train_standard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(x_train)\n",
    "X_test_scaled = scaler.transform(x_test)\n",
    "svm_model = SVC(kernel='linear', C=1.0, probability=True, random_state=42)\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "y_pred = svm_model.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11,  1,  0, ..., 11,  5,  2], dtype=int64)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_flattened = y_train.argmax(axis=1)\n",
    "y_flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input unsorted array :  [0.12681672 0.1958262  0.28140433 0.04834938 0.07772    0.02590886\n",
      " 0.06871412 0.04280739 0.05009817 0.04869181 0.03366302]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.28140433, 0.1958262 , 0.12681672])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input array\n",
    "in_arr = np.array([0.12681672, 0.1958262 , 0.28140433 ,0.04834938 ,0.07772  ,  0.02590886,\n",
    " 0.06871412, 0.04280739, 0.05009817 ,0.04869181 ,0.03366302])\n",
    "print(\"Input unsorted array : \", in_arr)\n",
    " \n",
    "sorted_indices = np.argsort(in_arr)[::-1]\n",
    "top_k_indices = sorted_indices[:3]\n",
    "y_score_k = np.array(in_arr)[top_k_indices]\n",
    "y_score_k"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Golden Scenario Env",
   "language": "python",
   "name": "golden_scenario_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
